{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laboratorio 3(Regresion logistica One vs All) Grupo 1\n",
    " <h3>Implementacion del modelo de regresion logistica one-vs-all para realizar clasificacion de clases.<h3>\n",
    " <HR>\n",
    " <h3>\n",
    "  NOMBRE: POLO ORELLANA BRAYAN SIMON <br>\n",
    "  CARRERA: INGENIERIA DE SISTEMAS <BR>\n",
    "  FECHA: 19/03/2024 <BR>\n",
    "\n",
    "  * [Enlace de invitacion para ser colaborador](https://github.com/bspoloo/SIS420-012024/invitations)\n",
    "  \n",
    "  * [Enlace al git hub](https://github.com/bspoloo/SIS420-012024/tree/main/Laboratorios/Laboratorio%203)\n",
    "  \n",
    "  * [Enlace al Colab](https://colab.research.google.com/github/bspoloo/SIS420-012024/blob/main/Laboratorios/Laboratorio%203/Laboratorio%203.ipynb?hl=es)\n",
    "  \n",
    " <h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para el laboratorio se hizo uso del para entrenar el modelo de **Regresion Logistica one vs all** y dada la información relacionada con el crédito de una persona, se creo un modelo de aprendizaje automático que pueda clasificar el puntaje crediticio de una persona\n",
    "\n",
    " A lo largo de los años, se han recopilado datos bancarios básicos y mucha información relacionada con el crédito de varias personas. Se quiere construir un sistema inteligente para segregar a las personas en tramos de puntuación crediticia para reducir los esfuerzos manuales. Haciendo uso del siguiente dataset: [credit_score_classification_processed](https://www.kaggle.com/datasets/deepaksaipendyala/credit-score-classification-processed).\n",
    "\n",
    "El archivo `credit_score.csv` contiene un conjunto de datos de entrenamiento para clasificar el puntaje crediticio de una persona."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Clasificacion multiclase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importamos todas las librerias necesarias para el manejo del dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utilizando la libreria os para manejos de directorios\n",
    "import os\n",
    "\n",
    "# Computacion vectorial y cientifica para python\n",
    "import numpy as np  \n",
    "\n",
    "#importamos pandas para el manejo del dataset, y separarlos dentro de una matriz\n",
    "import pandas as pd\n",
    "\n",
    "#esta tabulate nos sirve para hacer tablas\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Librerias para graficación (trazado de gráficos)\n",
    "from matplotlib import pyplot\n",
    "from mpl_toolkits.mplot3d import Axes3D  # -> Necesario para graficar superficies 3D\n",
    "\n",
    "#Para separa el 20% y 80%\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Modulo de optimizacion en scipy\n",
    "from scipy import optimize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Cargamos los datos del dataset\n",
    "cargamos los datos haciendo el uso de la libreria **Pandas** que  es una herramienta poderosa y versátil utilizada para manipulación y análisis de datos. Ofrece estructuras de datos flexibles y eficientes para trabajar con datos tabulares, como hojas de cálculo en Excel o tablas SQL.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Month</th>\n",
       "      <th>Age</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Annual_Income</th>\n",
       "      <th>Monthly_Inhand_Salary</th>\n",
       "      <th>Num_Bank_Accounts</th>\n",
       "      <th>Num_Credit_Card</th>\n",
       "      <th>Interest_Rate</th>\n",
       "      <th>Num_of_Loan</th>\n",
       "      <th>Type_of_Loan</th>\n",
       "      <th>...</th>\n",
       "      <th>Credit_Mix</th>\n",
       "      <th>Outstanding_Debt</th>\n",
       "      <th>Credit_Utilization_Ratio</th>\n",
       "      <th>Credit_History_Age</th>\n",
       "      <th>Payment_of_Min_Amount</th>\n",
       "      <th>Total_EMI_per_month</th>\n",
       "      <th>Amount_invested_monthly</th>\n",
       "      <th>Payment_Behaviour</th>\n",
       "      <th>Monthly_Balance</th>\n",
       "      <th>Credit_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>13</td>\n",
       "      <td>19114.12</td>\n",
       "      <td>4194.170850</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>128</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>809.98</td>\n",
       "      <td>31.944960</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>49.574949</td>\n",
       "      <td>118.280222</td>\n",
       "      <td>3</td>\n",
       "      <td>284.629162</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>34.429817</td>\n",
       "      <td>13</td>\n",
       "      <td>19114.12</td>\n",
       "      <td>4194.170850</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>128</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>809.98</td>\n",
       "      <td>28.609352</td>\n",
       "      <td>267</td>\n",
       "      <td>1</td>\n",
       "      <td>49.574949</td>\n",
       "      <td>81.699521</td>\n",
       "      <td>4</td>\n",
       "      <td>331.209863</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>13</td>\n",
       "      <td>19114.12</td>\n",
       "      <td>4194.170850</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>128</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>809.98</td>\n",
       "      <td>31.377862</td>\n",
       "      <td>268</td>\n",
       "      <td>1</td>\n",
       "      <td>49.574949</td>\n",
       "      <td>199.458074</td>\n",
       "      <td>5</td>\n",
       "      <td>223.451310</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>13</td>\n",
       "      <td>19114.12</td>\n",
       "      <td>1824.843333</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>128</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>809.98</td>\n",
       "      <td>24.797347</td>\n",
       "      <td>269</td>\n",
       "      <td>1</td>\n",
       "      <td>49.574949</td>\n",
       "      <td>41.420153</td>\n",
       "      <td>1</td>\n",
       "      <td>341.489231</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>13</td>\n",
       "      <td>19114.12</td>\n",
       "      <td>4194.170850</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>128</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>809.98</td>\n",
       "      <td>27.262259</td>\n",
       "      <td>270</td>\n",
       "      <td>1</td>\n",
       "      <td>49.574949</td>\n",
       "      <td>62.430172</td>\n",
       "      <td>6</td>\n",
       "      <td>340.479212</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79800</th>\n",
       "      <td>1</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>20002.88</td>\n",
       "      <td>1929.906667</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4913</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3571.70</td>\n",
       "      <td>37.140784</td>\n",
       "      <td>75</td>\n",
       "      <td>2</td>\n",
       "      <td>60.964772</td>\n",
       "      <td>34.662906</td>\n",
       "      <td>0</td>\n",
       "      <td>337.362988</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79801</th>\n",
       "      <td>2</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>9</td>\n",
       "      <td>39628.99</td>\n",
       "      <td>3359.415833</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>683</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>502.38</td>\n",
       "      <td>29.135447</td>\n",
       "      <td>376</td>\n",
       "      <td>1</td>\n",
       "      <td>58638.000000</td>\n",
       "      <td>180.733095</td>\n",
       "      <td>4</td>\n",
       "      <td>400.104466</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79802</th>\n",
       "      <td>5</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>9</td>\n",
       "      <td>39628.99</td>\n",
       "      <td>3359.415833</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>14.546679</td>\n",
       "      <td>2.0</td>\n",
       "      <td>683</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>502.38</td>\n",
       "      <td>41.255522</td>\n",
       "      <td>380</td>\n",
       "      <td>1</td>\n",
       "      <td>35.104023</td>\n",
       "      <td>24.028477</td>\n",
       "      <td>0</td>\n",
       "      <td>516.809083</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79803</th>\n",
       "      <td>4</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>9</td>\n",
       "      <td>39628.99</td>\n",
       "      <td>3359.415833</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>683</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>502.38</td>\n",
       "      <td>33.638208</td>\n",
       "      <td>381</td>\n",
       "      <td>1</td>\n",
       "      <td>35.104023</td>\n",
       "      <td>251.672582</td>\n",
       "      <td>3</td>\n",
       "      <td>319.164979</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79804</th>\n",
       "      <td>1</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>9</td>\n",
       "      <td>39628.99</td>\n",
       "      <td>3359.415833</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>683</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>502.38</td>\n",
       "      <td>34.192463</td>\n",
       "      <td>382</td>\n",
       "      <td>1</td>\n",
       "      <td>35.104023</td>\n",
       "      <td>167.163865</td>\n",
       "      <td>6</td>\n",
       "      <td>393.673696</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>79805 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Month        Age  Occupation  Annual_Income  Monthly_Inhand_Salary  \\\n",
       "0          2  23.000000          13       19114.12            4194.170850   \n",
       "1          6  34.429817          13       19114.12            4194.170850   \n",
       "2          0  23.000000          13       19114.12            4194.170850   \n",
       "3          7  23.000000          13       19114.12            1824.843333   \n",
       "4          5  23.000000          13       19114.12            4194.170850   \n",
       "...      ...        ...         ...            ...                    ...   \n",
       "79800      1  29.000000           1       20002.88            1929.906667   \n",
       "79801      2  25.000000           9       39628.99            3359.415833   \n",
       "79802      5  25.000000           9       39628.99            3359.415833   \n",
       "79803      4  25.000000           9       39628.99            3359.415833   \n",
       "79804      1  25.000000           9       39628.99            3359.415833   \n",
       "\n",
       "       Num_Bank_Accounts  Num_Credit_Card  Interest_Rate  Num_of_Loan  \\\n",
       "0                    3.0              4.0       3.000000          4.0   \n",
       "1                    3.0              4.0       3.000000          4.0   \n",
       "2                    3.0              4.0       3.000000          4.0   \n",
       "3                    3.0              4.0       3.000000          4.0   \n",
       "4                    3.0              4.0       3.000000          4.0   \n",
       "...                  ...              ...            ...          ...   \n",
       "79800               10.0              8.0      29.000000          5.0   \n",
       "79801                4.0              6.0       7.000000          2.0   \n",
       "79802                4.0              6.0      14.546679          2.0   \n",
       "79803                4.0              6.0       7.000000          2.0   \n",
       "79804                4.0              6.0       7.000000          2.0   \n",
       "\n",
       "       Type_of_Loan  ...  Credit_Mix  Outstanding_Debt  \\\n",
       "0               128  ...           1            809.98   \n",
       "1               128  ...           1            809.98   \n",
       "2               128  ...           1            809.98   \n",
       "3               128  ...           1            809.98   \n",
       "4               128  ...           1            809.98   \n",
       "...             ...  ...         ...               ...   \n",
       "79800          4913  ...           0           3571.70   \n",
       "79801           683  ...           1            502.38   \n",
       "79802           683  ...           1            502.38   \n",
       "79803           683  ...           1            502.38   \n",
       "79804           683  ...           1            502.38   \n",
       "\n",
       "       Credit_Utilization_Ratio  Credit_History_Age  Payment_of_Min_Amount  \\\n",
       "0                     31.944960                   0                      1   \n",
       "1                     28.609352                 267                      1   \n",
       "2                     31.377862                 268                      1   \n",
       "3                     24.797347                 269                      1   \n",
       "4                     27.262259                 270                      1   \n",
       "...                         ...                 ...                    ...   \n",
       "79800                 37.140784                  75                      2   \n",
       "79801                 29.135447                 376                      1   \n",
       "79802                 41.255522                 380                      1   \n",
       "79803                 33.638208                 381                      1   \n",
       "79804                 34.192463                 382                      1   \n",
       "\n",
       "       Total_EMI_per_month  Amount_invested_monthly  Payment_Behaviour  \\\n",
       "0                49.574949               118.280222                  3   \n",
       "1                49.574949                81.699521                  4   \n",
       "2                49.574949               199.458074                  5   \n",
       "3                49.574949                41.420153                  1   \n",
       "4                49.574949                62.430172                  6   \n",
       "...                    ...                      ...                ...   \n",
       "79800            60.964772                34.662906                  0   \n",
       "79801         58638.000000               180.733095                  4   \n",
       "79802            35.104023                24.028477                  0   \n",
       "79803            35.104023               251.672582                  3   \n",
       "79804            35.104023               167.163865                  6   \n",
       "\n",
       "       Monthly_Balance  Credit_Score  \n",
       "0           284.629162             2  \n",
       "1           331.209863             2  \n",
       "2           223.451310             2  \n",
       "3           341.489231             2  \n",
       "4           340.479212             2  \n",
       "...                ...           ...  \n",
       "79800       337.362988             1  \n",
       "79801       400.104466             1  \n",
       "79802       516.809083             0  \n",
       "79803       319.164979             1  \n",
       "79804       393.673696             0  \n",
       "\n",
       "[79805 rows x 24 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Haciendo uso de la libreria pandas para leer el dataset, delimitado por \",\"\n",
    "dataset = pd.read_csv('credit_score.csv', delimiter=',')\n",
    "\n",
    "#eliminamos la primera columan que seria nuestro \"id\" ya que no nos sirve para el analisis\n",
    "dataset = dataset.drop(dataset.columns[0], axis=1)\n",
    "\n",
    "#ahora tenemos un dataframe\n",
    "#Imprimimos en una tabla el dataset para hacer un analisis mas claro.\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mostrando la tabla nos damos cuenta que nuestra Y a predicir es el **Credit_Score**, para tener una mejor vision de la cantidad de clases que existe, se hizo el siguiente codigo:\n",
    "\n",
    "donde separamos nuestra columna Y con `value_counts()` este método de pandas cuenta el número de veces que aparece cada valor único en la columna **Credit_Score** del DataFrame. Devuelve una Serie pandas donde los índices son los valores únicos de la columna **Credit_Score** y los valores son el recuento de ocurrencias de cada valor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "la cantidad de caracteristicas es: 23\n",
      "la cantidad de clases es: 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Credit_Score\n",
       "1    42470\n",
       "0    23129\n",
       "2    14206\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#para contar cuantas clases contiene nuestra columna y\n",
    "class_counts = dataset[\"Credit_Score\"].value_counts()\n",
    "\n",
    "#para contar cuantas caracteristicas tiene nuestro dataset, obviamente con sin contar nuestra y, por eso lo dropeamos, tambien dropeamos la primera columna que no tiene nombre\n",
    "feactures_counts =dataset.drop(['Credit_Score'], axis=1)\n",
    "feactures_counts = feactures_counts.shape[1]\n",
    "\n",
    "print(f\"la cantidad de caracteristicas es: { feactures_counts}\")\n",
    "print(f'la cantidad de clases es: 3')\n",
    "\n",
    "#mostramos la cantidad de clases tiene, y en que cantidad\n",
    "class_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.1 Analisis del dataset:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hay 3 clases diferentes de puntajes crediticios: etiquetados como 0, 1 y 2.\n",
    "\n",
    "* La clase 1 parece ser la más común, seguida por la clase 0 y luego la clase 2.\n",
    "* El recuento de cada clase es el siguiente:\n",
    "    - Clase 0: 23129 personas.\n",
    "    - Clase 1: 42470 personas.\n",
    "    - Clase 2: 14206 personas.\n",
    "* Este análisis de la distribución de los puntajes crediticios en el conjunto de datos es útil para comprender la proporción de cada clase. Esto puede ser relevante al desarrollar un modelo de clasificación como la Regresión Logística one vs all. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#almacenamos la cantidad de caracteristicas en una variable\n",
    "input_layer_size  = feactures_counts;\n",
    "\n",
    "#almacenamos la cantidad de clases en una variable\n",
    "\n",
    "#para este caso no es necesario cambiar los valores de la ultima clase, ya que este cuenta con 0,1,2, \n",
    "# en caso de contener 1,2,3 se tendria que hacer los cambios necesarios para que sea 1,2,0, o simplememte suma 1 a la cantidad de clases.\n",
    "num_labels = 3;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.2 Separacion de datos\n",
    "Se debe tomar en cuenta que cada clase tiene su propia cantidad, por lo cual separarlos directamente en un 80% para entrenamiento y un 20% para test no seria tan efectivo, ya que puede que en el 80% hay mas datos de una clase que las otras, provocando que nuestro modelo no conozca mucho sobre esa clase, por lo cual debe separarse un 80% para entrenamiento y un 20% para pruebas de cada clase.\n",
    "\n",
    "Para este hacemos uso de la libreria **train_test_split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hacemos uso del DataFrame llamado 'dataset' que contiene nuestros datos datos\n",
    "# y es la columna que contiene las etiquetas de clase (en este caso, 'Credit_Score')\n",
    "\n",
    "#creamos una variable temporal que contentra toda la columna de 'Credit_Score'\n",
    "y_temp = dataset['Credit_Score']\n",
    "\n",
    "# Para la clase 0\n",
    "\n",
    "#donde y_temp es igual a 0, separamos los datos en train_class_0, test_class_0\n",
    "data_class_0 = dataset[y_temp == 0]\n",
    "train_class_0, test_class_0 = train_test_split(data_class_0, test_size=0.2, random_state=42)\n",
    "\n",
    "# Para la clase 1\n",
    "\n",
    "#donde y_temp es igual a 1, separamos los datos en train_class_1, test_class_1\n",
    "data_class_1 = dataset[y_temp == 1]\n",
    "train_class_1, test_class_1 = train_test_split(data_class_1, test_size=0.2, random_state=42)\n",
    "\n",
    "# Para la clase 2\n",
    "\n",
    "#donde y_temp es igual a 2, separamos los datos en train_class_2, test_class_2\n",
    "data_class_2 = dataset[y_temp == 2]\n",
    "train_class_2, test_class_2 = train_test_split(data_class_2, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "haciendo conteo de separacion de datos:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Para la clase 0 tenemos una cantidad de: 23129 donde el 80% es: 18503 y el 20% es: 4626\n",
      "Para la clase 1 tenemos una cantidad de: 42470 donde el 80% es: 33976 y el 20% es: 8494\n",
      "Para la clase 2 tenemos una cantidad de: 14206 donde el 80% es: 11364 y el 20% es: 2842\n",
      "La cantidad total de datos es: 79805\n"
     ]
    }
   ],
   "source": [
    "print(f\"Para la clase 0 tenemos una cantidad de: { data_class_0.shape[0]} donde el 80% es: {train_class_0.shape[0]} y el 20% es: {test_class_0.shape[0]}\")\n",
    "print(f\"Para la clase 1 tenemos una cantidad de: { data_class_1.shape[0]} donde el 80% es: {train_class_1.shape[0]} y el 20% es: {test_class_1.shape[0]}\")\n",
    "print(f\"Para la clase 2 tenemos una cantidad de: { data_class_2.shape[0]} donde el 80% es: {train_class_2.shape[0]} y el 20% es: {test_class_2.shape[0]}\")\n",
    "print(f\"La cantidad total de datos es: {dataset.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separamos cada uno en sus X_train, y_train, X_test y y_test respectivos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#para la parte de entrenamiento, separamos las caracteristicas de la etiqueta\n",
    "\n",
    "#para la clase 0\n",
    "X_train_class_0 = train_class_0.drop(['Credit_Score'], axis=1)\n",
    "y_train_class_0 = train_class_0['Credit_Score']\n",
    "\n",
    "#para la clase 1\n",
    "X_train_class_1 = train_class_1.drop(['Credit_Score'], axis=1)\n",
    "y_train_class_1 = train_class_1['Credit_Score']\n",
    "\n",
    "#para la clase 2\n",
    "X_train_class_2 = train_class_2.drop(['Credit_Score'], axis=1)\n",
    "y_train_class_2 = train_class_2['Credit_Score']\n",
    "\n",
    "#ahora para la parte de pruebas, separamos las caracteristicas de la etiqueta\n",
    "#para la clase 0\n",
    "X_test_class_0 = test_class_0.drop(['Credit_Score'], axis=1)\n",
    "y_test_class_0 = test_class_0['Credit_Score']\n",
    "\n",
    "#para la clase 1\n",
    "X_test_class_1 = test_class_1.drop(['Credit_Score'], axis=1)\n",
    "y_test_class_1 = test_class_1['Credit_Score']\n",
    "\n",
    "#para la clase 2\n",
    "X_test_class_2 = test_class_2.drop(['Credit_Score'], axis=1)\n",
    "y_test_class_2 = test_class_2['Credit_Score']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ahora unimos todos en una sola matriz para X y y:\n",
    "pero luego debemos mezclar los datos, haciendo uso de ``np.random.permutation(len(X))`` genera un arreglo de índices permutados aleatoriamente.\n",
    "Luego, estos índices se usan para reorganizar tanto las características como las etiquetas de entrenamiento y prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#separando los datos de entrenamiento y pruebas\n",
    "\n",
    "#para los datos de entrenamiento\n",
    "X_train = pd.concat([X_train_class_0, X_train_class_1, X_train_class_2]).values\n",
    "y_train = pd.concat([y_train_class_0, y_train_class_1, y_train_class_2]).values\n",
    "\n",
    "\n",
    "indices_train = np.random.permutation(len(X_train))\n",
    "X_train = X_train[indices_train]\n",
    "y_train = y_train[indices_train]\n",
    "m_train = len(y_train)\n",
    "\n",
    "#para los datos de pruebas\n",
    "X_test = pd.concat([X_test_class_0, X_test_class_1, X_test_class_2]).values\n",
    "y_test = pd.concat([y_test_class_0, y_test_class_1, y_test_class_2]).values\n",
    "\n",
    "indices_test = np.random.permutation(len(X_test))\n",
    "X_test = X_test[indices_test]\n",
    "y_test = y_test[indices_test]\n",
    "m_test = len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizamos algunos datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    X[:,0]   X[:, 1]   X[:, 2]   X[:, 3]   X[:, 4]   X[:, 5]   X[:, 6]   X[:, 7]   X[:, 8]   X[:, 9]  X[:, 10]  X[:, 11]  X[:, 12]  X[:, 13]  X[:, 14]  X[:, 15]  X[:, 16]  X[:, 17]  X[:, 18]  X[:, 19]  X[:, 20]  X[:, 21]  X[:, 22]     Y\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "         3        28        15     19221      1882         6       6        30         6      2654        43        22      2114        10         0      2669        32       115         2        67        48         0       314       0\n",
      "         0        30         5     30000      2768        10       9        15         5       473        42        20      3966        10         0      2593        34       196         2       102        47         1       378       0\n",
      "         1        41        15     18330      1312         7       6         6         6      5129        17        11      1920         6         2       161        35       239         0        52       176         5       193       1\n",
      "         7        24        12     61219      4861        10       6        16         6      1464        42        16      3455        14         0      2463        37       121         2       263       322         2       161       0\n",
      "         1        27         0     36190      4194         5       3        10         0      6260        11        31      2232         5         1      1407        33       192         1         0        35         1       541       1\n",
      "         6        31         4     28562      2610         9       5        32         9       975        57        17      2437        13         0      3624        28       117         2       201       282         5        68       1\n",
      "         6        36        11     28486      4194         8       5         5         1      5591        16        15      2033         5         2       339        38         0         2        17       340         5       197       1\n",
      "         5        34         7     64923      4194         8       3         5         3      5267         8        31      4206         6         2       370        24       372         2       157       387         5       298       1\n",
      "         4        38        11     44769      3912         6      10        29         4      2104        47        17      1136         8         0      2287        40       202         2        96       124         1       421       0\n",
      "         5        46         9  22828106      4194         0       3         5         3      3524         1         6       872         3         1       822        39       267         1     82178        77         0       985       2\n",
      " \n",
      "El 80% de ejemplos para entrenamiento son la cantidad de: 63843 de ejemplos\n",
      "El 20% de ejemplos para pruebas son la cantidad de: 15962 de ejemplos\n"
     ]
    }
   ],
   "source": [
    "print('{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>6s}'.format(\n",
    "    'X[:,0]', 'X[:, 1]', 'X[:, 2]', 'X[:, 3]', 'X[:, 4]', 'X[:, 5]', 'X[:, 6]', 'X[:, 7]', 'X[:, 8]', 'X[:, 9]', 'X[:, 10]', 'X[:, 11]', 'X[:, 12]', \n",
    "    'X[:, 13]', 'X[:, 14]', 'X[:, 15]', 'X[:, 16]', 'X[:, 17]', 'X[:, 18]', 'X[:, 19]', 'X[:, 20]', 'X[:, 21]', 'X[:, 22]','Y'\n",
    "))\n",
    "print('-' * 250)\n",
    "\n",
    "for i in range(10):\n",
    "    print('{:10.0f}{:10.0f}{:10.0f}{:10.0f}{:10.0f}{:10.0f}{:8.0f}{:10.0f}{:10.0f}{:10.0f}{:10.0f}{:10.0f}{:10.0f}{:10.0f}{:10.0f}{:10.0f}{:10.0f}{:10.0f}{:10.0f}{:10.0f}{:10.0f}{:10.0f}{:10.0f}{:8.0f}'.format(\n",
    "        X_train[i, 0],\n",
    "        X_train[i, 1],\n",
    "        X_train[i, 2], \n",
    "        X_train[i, 3], \n",
    "        X_train[i, 4], \n",
    "        X_train[i, 5], \n",
    "        X_train[i, 6], \n",
    "        X_train[i, 7], \n",
    "        X_train[i, 8], \n",
    "        X_train[i, 9], \n",
    "        X_train[i, 10],\n",
    "        X_train[i, 11],\n",
    "        X_train[i, 12], \n",
    "        X_train[i, 13], \n",
    "        X_train[i, 14], \n",
    "        X_train[i, 15], \n",
    "        X_train[i, 16],\n",
    "        X_train[i, 17],\n",
    "        X_train[i, 18],\n",
    "        X_train[i, 19], \n",
    "        X_train[i, 20], \n",
    "        X_train[i, 21], \n",
    "        X_train[i, 22], \n",
    "        y_train[i]\n",
    "    ))\n",
    "\n",
    "#mostramos la cantidad de ejemplos\n",
    "print(\" \")\n",
    "print('El 80% de ejemplos para entrenamiento son la cantidad de: {:.0f} de ejemplos'.format( len(X_train)))\n",
    "print('El 20% de ejemplos para pruebas son la cantidad de: {:.0f} de ejemplos'.format(  len(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Normalización de caracteristicas\n",
    "\n",
    "Al visualizar los datos se puede observar que las caracteristicas tienen diferentes magnitudes, por lo cual se debe transformar cada valor en una escala de valores similares, esto con el fin de que el descenso por el gradiente pueda converger mas rapidamente. Se aplica la normalizacion esto debido a que los datos de las X estan a diferentes escalas.\n",
    "\n",
    "Hacemos el uso de la siguiente funcion para normalizar los datos de las columnas X:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def  featureNormalize(X):\n",
    "    X_norm = X.copy()\n",
    "\n",
    "    #creamos un array de ceros con una longitud igual al número de columnas en el array X. La variable mu y sigma se inicializa como este array de ceros.\n",
    "    mu = np.zeros(X.shape[1])\n",
    "    sigma = np.zeros(X.shape[1])\n",
    "\n",
    "    #Creamos el promedio de cada columna de X\n",
    "    mu = np.mean(X, axis = 0)\n",
    "    sigma = np.std(X, axis = 0)\n",
    "    \n",
    "    sigma[sigma == 0] = 1\n",
    "    \n",
    "    #normalizamos los datos con la siguiente formula\n",
    "    X_norm = (X - mu) / sigma\n",
    "\n",
    "    return X_norm, mu, sigma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalizando las caracteristicas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    X[:,0]   X[:, 1]   X[:, 2]   X[:, 3]   X[:, 4]   X[:, 5]   X[:, 6]   X[:, 7]   X[:, 8]   X[:, 9]  X[:, 10]  X[:, 11]  X[:, 12]  X[:, 13]  X[:, 14]  X[:, 15]  X[:, 16]  X[:, 17]  X[:, 18]  X[:, 19]  X[:, 20]  X[:, 21]  X[:, 22]     Y\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "     -0.21     -0.66      1.63     -0.11     -0.79      0.20     -0.00      1.77      1.00     -0.43      1.47     -0.04     -0.33     -0.09     -1.51      1.07      0.01     -0.75      0.86     -0.16     -0.30     -1.52     -0.42       0\n",
      "     -1.52     -0.46     -0.54     -0.10     -0.49      1.55      1.15      0.05      0.59     -1.54      1.41     -0.05      1.17     -0.09     -1.51      1.00      0.38     -0.04      0.86     -0.16     -0.30     -1.01     -0.12       0\n",
      "     -1.09      0.68      1.63     -0.11     -0.99      0.54      0.13     -0.98      1.00      0.82     -0.27     -0.09     -0.49     -0.11      0.97     -1.09      0.56      0.33     -2.02     -0.16     -0.23      1.01     -0.99       1\n",
      "      1.53     -1.08      0.98     -0.08      0.22      1.55      0.13      0.17      1.00     -1.03      1.41     -0.07      0.76     -0.07     -1.51      0.89      0.84     -0.70      0.86     -0.14     -0.16     -0.51     -1.14       0\n",
      "     -1.09     -0.77     -1.63     -0.10     -0.00     -0.14     -0.89     -0.52     -1.45      1.39     -0.68     -0.00     -0.23     -0.12     -0.27     -0.02      0.13     -0.08     -0.58     -0.17     -0.30     -1.01      0.65       1\n",
      "      1.09     -0.35     -0.76     -0.11     -0.54      1.21     -0.21      2.00      2.23     -1.28      2.42     -0.06     -0.07     -0.08     -1.51      1.89     -0.85     -0.74      0.86     -0.15     -0.18      1.01     -1.57       1\n",
      "      1.09      0.16      0.76     -0.11     -0.00      0.88     -0.21     -1.09     -1.04      1.06     -0.34     -0.07     -0.39     -0.12      0.97     -0.94      1.11     -1.76      0.86     -0.17     -0.15      1.01     -0.97       1\n",
      "      0.66      0.00     -0.11     -0.08     -0.00      0.88     -0.89     -1.09     -0.22      0.89     -0.88     -0.00      1.37     -0.11      0.97     -0.91     -1.52      1.49      0.86     -0.15     -0.13      1.01     -0.49       1\n",
      "      0.22      0.37      0.76     -0.09     -0.10      0.20      1.48      1.66      0.18     -0.71      1.74     -0.06     -1.12     -0.10     -1.51      0.74      1.45      0.01      0.86     -0.16     -0.26     -1.01      0.08       0\n",
      "      0.66      1.19      0.33     15.45     -0.00     -1.82     -0.89     -1.09     -0.22      0.01     -1.35     -0.11     -1.33     -0.13     -0.27     -0.52      1.29      0.58     -0.58      9.70     -0.28     -1.52      2.73       2\n"
     ]
    }
   ],
   "source": [
    "X_norm, mu, sigma= featureNormalize(X_train)\n",
    "\n",
    "# imprimir todos las X_norm de datos solo 10\n",
    "print('{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>6s}'.format(\n",
    "    'X[:,0]', 'X[:, 1]', 'X[:, 2]', 'X[:, 3]', 'X[:, 4]', 'X[:, 5]', 'X[:, 6]', 'X[:, 7]', 'X[:, 8]', 'X[:, 9]', 'X[:, 10]', 'X[:, 11]', 'X[:, 12]', \n",
    "    'X[:, 13]', 'X[:, 14]', 'X[:, 15]', 'X[:, 16]', 'X[:, 17]', 'X[:, 18]', 'X[:, 19]', 'X[:, 20]', 'X[:, 21]', 'X[:, 22]','Y'\n",
    "))\n",
    "print('-' * 250)\n",
    "\n",
    "for i in range(10):\n",
    "    print('{:10.2f}{:10.2f}{:10.2f}{:10.2f}{:10.2f}{:10.2f}{:10.2f}{:10.2f}{:10.2f}{:10.2f}{:10.2f}{:10.2f}{:10.2f}{:10.2f}{:10.2f}{:10.2f}{:10.2f}{:10.2f}{:10.2f}{:10.2f}{:10.2f}{:10.2f}{:10.2f}{:8.0f}'.format(\n",
    "        X_norm[i, 0],\n",
    "        X_norm[i, 1],\n",
    "        X_norm[i, 2], \n",
    "        X_norm[i, 3], \n",
    "        X_norm[i, 4], \n",
    "        X_norm[i, 5], \n",
    "        X_norm[i, 6], \n",
    "        X_norm[i, 7], \n",
    "        X_norm[i, 8], \n",
    "        X_norm[i, 9], \n",
    "        X_norm[i, 10],\n",
    "        X_norm[i, 11],\n",
    "        X_norm[i, 12], \n",
    "        X_norm[i, 13], \n",
    "        X_norm[i, 14], \n",
    "        X_norm[i, 15], \n",
    "        X_norm[i, 16],\n",
    "        X_norm[i, 17],\n",
    "        X_norm[i, 18],\n",
    "        X_norm[i, 19], \n",
    "        X_norm[i, 20], \n",
    "        X_norm[i, 21], \n",
    "        X_norm[i, 22], \n",
    "        y_train[i]\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Creacion de la funcion Sigmoide\n",
    "También conocida como la función logística, es una función matemática que toma cualquier número real como entrada y devuelve un valor en el rango de 0 a 1. Donde nuestra **Z** es nuestra hipotesis.\n",
    "\n",
    "Creando la funcion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    z = np.array(z)\n",
    "\n",
    "    g = np.zeros(z.shape)\n",
    "\n",
    "    g = 1 / (1 + np.exp(-z))\n",
    "\n",
    "    return g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Funcion de costo\n",
    "Aplicando la teoria donde nuestra funcion recibira parametros como Theta, x, y y lamda_, donde lamda_ es nuestro parametro de regularizacion.\n",
    "\n",
    "Donde la funcion nos devuelve un costo y nuestro gradiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lrCostFunction(theta, X, y, lambda_):\n",
    "    #creamos una variable m que contiene la longitud de y\n",
    "    m = y.size\n",
    "\n",
    "    # convierte las etiquetas a valores enteros si son boleanos\n",
    "    if y.dtype == bool:\n",
    "        y = y.astype(int)\n",
    "\n",
    "    #inicializamos J y grad\n",
    "    J = 0\n",
    "    grad = np.zeros(theta.shape)\n",
    "\n",
    "    #calculamos h haciendo uso de la funcion sigmoid, donde h es nuestra hipotesis\n",
    "    h = sigmoid(X.dot(theta.T))\n",
    "\n",
    "    temp = theta\n",
    "    temp[0] = 0\n",
    "\n",
    "    J = (1 / m) * np.sum(-y.dot(np.log(h)) - (1 - y).dot(np.log(1 - h))) + (lambda_ / (2 * m)) * np.sum(np.square(temp))\n",
    "\n",
    "    grad = (1 / m) * (h - y).dot(X)\n",
    "    \n",
    "    grad = grad + (lambda_ / m) * temp\n",
    "\n",
    "    return J, grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Clasificacion One-vs-All\n",
    "Aqui estariamos usando un ciclo for para iterar sobre cada una de las clases, luego haciendo uso de `optimize.minimize` que es un método de la biblioteca *scipy* que encuentra el mínimo de una función. En este caso, se trata de minimizar la función de costos de regresión logística `(lrCostFunction)`.\n",
    "\n",
    "Los parámetros iniciales ``(initial_theta)``.\n",
    "Una tupla que contiene los datos de entrenamiento ``(X)``, las etiquetas ``(y == c)``, y el parámetro de regularización ``(lambda_)``.\n",
    "``jac=True`` indica que la función de coste devuelve tanto el coste como el gradiente.\n",
    "El método de optimización ``('CG' significa Gradiente Conjugado).``\n",
    "El diccionario de opciones ``(options)``  que se establece en 1000 para limitar el número máximo de iteraciones del optimizador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oneVsAll(X, y, num_labels, lambda_):\n",
    "    # algunas variables utiles\n",
    "    #m es la longitud de y, n es la cantidad de columnas en X\n",
    "    m, n = X.shape\n",
    "\n",
    "    # inicializamos la matriz de thetas con ceros, y con n+1 columnas que seria nuestro sesgo\n",
    "    all_theta = np.zeros((num_labels, n + 1))\n",
    "\n",
    "    # Agrega unos a la matriz X\n",
    "    X = np.concatenate([np.ones((m, 1)), X], axis=1)\n",
    "\n",
    "    # iteramos sobre cada etiqueta (clase) y entrenamos un clasificador\n",
    "    for c in np.arange(num_labels):\n",
    "        initial_theta = np.zeros(n + 1)\n",
    "        options = {'maxiter': 1000}\n",
    "        res = optimize.minimize(lrCostFunction,\n",
    "                                initial_theta,\n",
    "                                (X, (y == c), lambda_),\n",
    "                                jac=True,\n",
    "                                method='CG',\n",
    "                                options=options)\n",
    "\n",
    "        all_theta[c] = res.x\n",
    "\n",
    "    return all_theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inicializamos nuestra lambda con valor de *0.005*, usamos la funcion de `oneVsAll` donde pasamos los parametros de *X_norm*, *num_labels* que seria la cantidad de clases que tenemos, y nuestro *lanbda* para asi obtener nuestros Thetas para cada clase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 24)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "lambda_ = 0.005\n",
    "all_theta = oneVsAll(X_norm, y_train, num_labels, lambda_)\n",
    "print(all_theta.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thetha 0  para la clase 0: -1.081543148619021  ;  Thetha 0  para la clase 1: 0.14285348465754039  ;  Thetha 0  para la clase 2: -2.371132391239196\n",
      "Thetha 1  para la clase 0: 0.0014111350123358936  ;  Thetha 1  para la clase 1: 0.016860051168269403  ;  Thetha 1  para la clase 2: -0.03736392896826251\n",
      "Thetha 2  para la clase 0: -0.06071940308801994  ;  Thetha 2  para la clase 1: 0.007170383640216165  ;  Thetha 2  para la clase 2: 0.04980243075604156\n",
      "Thetha 3  para la clase 0: 0.007170501633783687  ;  Thetha 3  para la clase 1: -0.0011672846659346171  ;  Thetha 3  para la clase 2: -0.014865592155955183\n",
      "Thetha 4  para la clase 0: -0.02492779318261062  ;  Thetha 4  para la clase 1: 0.0211529044503502  ;  Thetha 4  para la clase 2: -0.001077602282414906\n",
      "Thetha 5  para la clase 0: -0.09457652584528718  ;  Thetha 5  para la clase 1: -0.004293661515637002  ;  Thetha 5  para la clase 2: 0.1232058635687482\n",
      "Thetha 6  para la clase 0: -0.020546861565206725  ;  Thetha 6  para la clase 1: 0.15972877816273517  ;  Thetha 6  para la clase 2: -0.044970750758277216\n",
      "Thetha 7  para la clase 0: 0.15747466010988934  ;  Thetha 7  para la clase 1: 0.025964032462834335  ;  Thetha 7  para la clase 2: -0.6243272857000183\n",
      "Thetha 8  para la clase 0: 0.545793250920604  ;  Thetha 8  para la clase 1: -0.20729124897517678  ;  Thetha 8  para la clase 2: -0.5822066121958983\n",
      "Thetha 9  para la clase 0: 0.062129784334892094  ;  Thetha 9  para la clase 1: 0.05664267679436485  ;  Thetha 9  para la clase 2: -0.21385356409212236\n",
      "Thetha 10  para la clase 0: -0.025236677878916376  ;  Thetha 10  para la clase 1: 0.025297882804004895  ;  Thetha 10  para la clase 2: -0.017037019837464605\n",
      "Thetha 11  para la clase 0: 0.30854462906925695  ;  Thetha 11  para la clase 1: -0.005075786279944824  ;  Thetha 11  para la clase 2: -0.6243381000453205\n",
      "Thetha 12  para la clase 0: 0.0007755589340439173  ;  Thetha 12  para la clase 1: 0.010405685022179981  ;  Thetha 12  para la clase 2: -0.01767986691580968\n",
      "Thetha 13  para la clase 0: 0.032423772488244254  ;  Thetha 13  para la clase 1: -0.029571678455976948  ;  Thetha 13  para la clase 2: 0.015414344875980202\n",
      "Thetha 14  para la clase 0: 0.004828484754207329  ;  Thetha 14  para la clase 1: -0.0007042485800947989  ;  Thetha 14  para la clase 2: -0.008176170946479586\n",
      "Thetha 15  para la clase 0: -0.2185688080824547  ;  Thetha 15  para la clase 1: 0.7232273056262929  ;  Thetha 15  para la clase 2: -0.9664257582457269\n",
      "Thetha 16  para la clase 0: 0.010831979809599213  ;  Thetha 16  para la clase 1: 0.12282938955543743  ;  Thetha 16  para la clase 2: -0.42206063803997396\n",
      "Thetha 17  para la clase 0: 0.010687326620320004  ;  Thetha 17  para la clase 1: -0.006597009660749987  ;  Thetha 17  para la clase 2: -0.007148585989304377\n",
      "Thetha 18  para la clase 0: -0.11194289822659181  ;  Thetha 18  para la clase 1: -0.006518559479318166  ;  Thetha 18  para la clase 2: 0.13038108022686581\n",
      "Thetha 19  para la clase 0: 0.02823308075016595  ;  Thetha 19  para la clase 1: 0.1117625859581561  ;  Thetha 19  para la clase 2: -0.2213360827634224\n",
      "Thetha 20  para la clase 0: -0.009421480398080011  ;  Thetha 20  para la clase 1: 0.007029768107026731  ;  Thetha 20  para la clase 2: -0.0036932736559365134\n",
      "Thetha 21  para la clase 0: -0.0010918752579677055  ;  Thetha 21  para la clase 1: -0.009778258357693012  ;  Thetha 21  para la clase 2: 0.022259438222133845\n",
      "Thetha 22  para la clase 0: 0.16311147232544623  ;  Thetha 22  para la clase 1: -0.04467713812481887  ;  Thetha 22  para la clase 2: -0.18493080358651975\n",
      "Thetha 23  para la clase 0: 0.1275179508368398  ;  Thetha 23  para la clase 1: 0.005893736798693515  ;  Thetha 23  para la clase 2: -0.19914752573399266\n"
     ]
    }
   ],
   "source": [
    "for i in range(all_theta.shape[1]):\n",
    "    print(\"Thetha\",i,\" para la clase 0:\", all_theta[0,i],\" ; \", \"Thetha\",i,\" para la clase 1:\", all_theta[1,i],\" ; \", \"Thetha\",i,\" para la clase 2:\", all_theta[2,i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.5.1 Prediccion One-vs-all\n",
    "Aqui creamos solo la funcion, donde mandamos los parametros de `all_theta` y la `X` que en este caso puede ser las X de prueba, pero antes deben de estar normalizadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictOneVsAll(all_theta, X):\n",
    "    m = X.shape[0];\n",
    "    num_labels = all_theta.shape[0]\n",
    "\n",
    "    p = np.zeros(m)\n",
    "\n",
    "    # añadimos unos a la matriz de X\n",
    "    X = np.concatenate([np.ones((m, 1)), X], axis=1)\n",
    "    p = np.argmax(sigmoid(X.dot(all_theta.T)), axis = 1)\n",
    "\n",
    "    return p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6 Validaciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para este caso de validacion se hizo uso de la funcion de `predictOneVsAll()` creada anteriormente, los siguiente fue normalizar nuestra `X_test` que son el 20% para pruebas, ahora se procedio a normalizarlo haciendo uso de *mu* y *sigma* calculado anteriormente en la funcion de normalizacion.\n",
    "\n",
    "luego se hace uso de `np.mean` donde nos calcula el promedio de los valores booleanos en el array resultante de la comparación. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.6.1 Con los datos de entrenamiento\n",
    "Para este caso se uso los datos de `X_norm` usando la funcion de `predictOneVsAll()`, viendo el resultado de precision nos da un **62%** el cual esta muy lejos de ser un buen modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision del conjunto de entrenamiento: 62.00%\n"
     ]
    }
   ],
   "source": [
    "# print(X_test.shape)\n",
    "pred_test = predictOneVsAll(all_theta, X_norm)\n",
    "print('Precision del conjunto de entrenamiento: {:.2f}%'.format(np.mean(pred_test == y_train) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.6.2 con los datos de prueba\n",
    "Para este caso se uso los datos de `X_test`, luego se procedio a normalizar los datos. \n",
    "\n",
    "Usando la funcion de `predictOneVsAll()`, viendo el resultado de precision nos da un **62.24%** , un poco en diferencia a la anterior prediccion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision del conjunto de entrenamiento: 62.24%\n"
     ]
    }
   ],
   "source": [
    "X_test1 = X_test.copy()\n",
    "# print(X_test.shape)\n",
    "X_test = (X_test - mu) / sigma\n",
    "pred_train = predictOneVsAll(all_theta, X_test)\n",
    "print('Precision del conjunto de entrenamiento: {:.2f}%'.format(np.mean(pred_train == y_test) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso se puede hacer las predicciones usando directamente la funcion `sigmoid()`, y luego imprimimos 30 predicciones para ver que tanto se asemejan con nuestra Y predicha."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15962, 24)\n",
      "Prediccion: 0, Real: 1\n",
      "Prediccion: 2, Real: 2\n",
      "Prediccion: 2, Real: 2\n",
      "Prediccion: 0, Real: 1\n",
      "Prediccion: 1, Real: 1\n",
      "Prediccion: 2, Real: 1\n",
      "Prediccion: 2, Real: 1\n",
      "Prediccion: 1, Real: 1\n",
      "Prediccion: 1, Real: 1\n",
      "Prediccion: 1, Real: 1\n",
      "Prediccion: 0, Real: 1\n",
      "Prediccion: 0, Real: 0\n",
      "Prediccion: 0, Real: 0\n",
      "Prediccion: 1, Real: 2\n",
      "Prediccion: 1, Real: 1\n",
      "Prediccion: 1, Real: 2\n",
      "Prediccion: 2, Real: 2\n",
      "Prediccion: 1, Real: 0\n",
      "Prediccion: 1, Real: 0\n",
      "Prediccion: 1, Real: 0\n",
      "Prediccion: 1, Real: 0\n",
      "Prediccion: 0, Real: 0\n",
      "Prediccion: 1, Real: 2\n",
      "Prediccion: 1, Real: 0\n",
      "Prediccion: 1, Real: 1\n",
      "Prediccion: 1, Real: 1\n",
      "Prediccion: 1, Real: 1\n",
      "Prediccion: 1, Real: 1\n",
      "Prediccion: 0, Real: 0\n",
      "Prediccion: 0, Real: 1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#usando el mu y sigma calculado anteriormente, para realizar la normalizacion de los datos de prueba\n",
    "X_test1 = (X_test1 - mu) / sigma\n",
    "X_test1 = np.concatenate([np.ones((len(X_test1), 1)), X_test1], axis=1)\n",
    "\n",
    "print(X_test1.shape)\n",
    "\n",
    "#para este ejemplo, vamos a mostrar las predicciones de las primeras 30 predicciones\n",
    "p = np.argmax(sigmoid(X_test1.dot(all_theta.T)), axis = 1)\n",
    "\n",
    "for i in range(30):\n",
    "    print(f\"Prediccion: {p[i]}, Real: {y_test[i]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
