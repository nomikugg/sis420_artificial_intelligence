{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Laboratorio 2(Regresion logistica) Grupo 1\n",
    " <h3>Implementacion del modelo de regresion logistica para realizar predicciones.<h3>\n",
    " <HR>\n",
    " <h3>\n",
    "  NOMBRE: POLO ORELLANA BRAYAN SIMON <br>\n",
    "  CARRERA: INGENIERIA DE SISTEMAS <BR>\n",
    "  FECHA: 12/03/2024 <BR>\n",
    "\n",
    "  * [Enlace de invitacion para ser colaborador](https://github.com/bspoloo/SIS420-012024/invitations)\n",
    "  \n",
    "  * [Enlace al git hub](https://github.com/bspoloo/SIS420-012024/tree/main/Laboratorios/Laboratorio%202)\n",
    "  \n",
    "  * [Enlace al Colab](https://colab.research.google.com/github/bspoloo/SIS420-012024/blob/main/Laboratorios/Laboratorio%202/Laboratorio%202.ipynb?hl=es)\n",
    " <h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para el laboratorio hizo uso del para entrenar el modelo de **Regresion Logistica** y predecir si un paciente tiene alguna enfermedad cardiovascular.\n",
    "\n",
    "Estos problemas a menudo se deben a la aterosclerosis. Esta afección ocurre cuando la grasa y el colesterol se acumulan en las paredes del vaso sanguíneo (arteria). El enlace al dataset es [Cardiovascular Disease dataset](https://www.kaggle.com/datasets/sulianova/cardiovascular-disease-dataset).\n",
    "\n",
    "El archivo `cardiovascular_diseases_dv3.csv` contiene un conjunto de datos de entrenamiento de datos si un paciente tiene una enfermedad cardiovascular."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Regresion Logistica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizamos las respectivas importaciones de librerias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utilizando la libreria os para manejos de directorios\n",
    "import os\n",
    "\n",
    "# Computacion vectorial y cientifica para python\n",
    "import numpy as np\n",
    "\n",
    "#importamos pandas para el manejo del dataset, y separarlos dentro de una matriz\n",
    "import pandas as pd\n",
    "\n",
    "#esta tabulate nos sirve para hacer tablas\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Librerias para graficación (trazado de gráficos)\n",
    "from matplotlib import pyplot\n",
    "from mpl_toolkits.mplot3d import Axes3D  # -> Necesario para graficar superficies 3D\n",
    "\n",
    "#Para separa el 20% y 80%\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# llama a matplotlib a embeber graficas dentro de los cuadernillos\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Cargamos los datos del dataset\n",
    "cargamos los datos haciendo el uso de la libreria **Pandas** que  es una herramienta poderosa y versátil utilizada para manipulación y análisis de datos. Ofrece estructuras de datos flexibles y eficientes para trabajar con datos tabulares, como hojas de cálculo en Excel o tablas SQL. Algunas de las funcionalidades clave de pandas incluyen:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la siguiente tabla impresa se puede ver lo siguiente, el cual son las caracteristicas del dataset:\n",
    "\n",
    "**Variables de entrada(X):**\n",
    "\n",
    "1. **age(Edad).-** Se refiere a la edad del paciente en años.\n",
    "2. **gender(Genero).-** Hace referencia al genero del paciente, 1 si es hombre y 2 si es mujer.\n",
    "3. **height(Altura).-** Es la altura del paciente medido en cm.\n",
    "4. **weight(Peso).-** Es el peso del paciente medido en Kg\n",
    "5. **ap_hight(Presión arterial sistólica).-** Presión arterial sistólica del paciente.\n",
    "6. **ap_low(Presión arterial diastólica).-** Presión arterial diastólica del paciente.\n",
    "7. **cholesterol(Colesterol).-** Nivel de colesterol en el paciente donde. 1: normal, 2: por encima de lo normal, 3: muy por encima de lo normal.\n",
    "8. **glocose(Glucosa).-** Nivel de glucosa del paciente donde. 1: normal, 2: por encima de lo normal, 3: muy por encima de lo normal.\n",
    "9. **smoke(Fuma).-** Indica si el paciente fuma. 1:Si y 2:No.\n",
    "10. **alcohol(alcohol).-** Indica si el paciente consume alcohol. 1:Si y 2:No.\n",
    "11. **fhisycal activity(Actividad fisica).-** Indical si el paciente realiza algun tipo de actividad fisica donde. 1:Si y 2:No.\n",
    "\n",
    "**Variable de salida(y):**\n",
    "\n",
    "1. **cardiovascular disease(Enfermedad cardiovascular).-** Presencia o ausencia de enfermedad cardiovascular, donde: 1:Si y 2:No."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGE</th>\n",
       "      <th>GENDER</th>\n",
       "      <th>HEIGHT</th>\n",
       "      <th>WEIGHT</th>\n",
       "      <th>AP_HIGH</th>\n",
       "      <th>AP_LOW</th>\n",
       "      <th>CHOLESTEROL</th>\n",
       "      <th>GLUCOSE</th>\n",
       "      <th>SMOKE</th>\n",
       "      <th>ALCOHOL</th>\n",
       "      <th>PHYSICAL_ACTIVITY</th>\n",
       "      <th>CARDIO_DISEASE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>168</td>\n",
       "      <td>62</td>\n",
       "      <td>110</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>85</td>\n",
       "      <td>140</td>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>165</td>\n",
       "      <td>64</td>\n",
       "      <td>130</td>\n",
       "      <td>70</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48</td>\n",
       "      <td>2</td>\n",
       "      <td>169</td>\n",
       "      <td>82</td>\n",
       "      <td>150</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>56</td>\n",
       "      <td>100</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68778</th>\n",
       "      <td>53</td>\n",
       "      <td>2</td>\n",
       "      <td>168</td>\n",
       "      <td>76</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68779</th>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>158</td>\n",
       "      <td>126</td>\n",
       "      <td>140</td>\n",
       "      <td>90</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68780</th>\n",
       "      <td>52</td>\n",
       "      <td>2</td>\n",
       "      <td>183</td>\n",
       "      <td>105</td>\n",
       "      <td>180</td>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68781</th>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>72</td>\n",
       "      <td>135</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68782</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>170</td>\n",
       "      <td>72</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>68783 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       AGE  GENDER  HEIGHT  WEIGHT  AP_HIGH  AP_LOW  CHOLESTEROL  GLUCOSE  \\\n",
       "0       50       2     168      62      110      80            1        1   \n",
       "1       55       1     156      85      140      90            3        1   \n",
       "2       52       1     165      64      130      70            3        1   \n",
       "3       48       2     169      82      150     100            1        1   \n",
       "4       48       1     156      56      100      60            1        1   \n",
       "...    ...     ...     ...     ...      ...     ...          ...      ...   \n",
       "68778   53       2     168      76      120      80            1        1   \n",
       "68779   62       1     158     126      140      90            2        2   \n",
       "68780   52       2     183     105      180      90            3        1   \n",
       "68781   61       1     163      72      135      80            1        2   \n",
       "68782   56       1     170      72      120      80            2        1   \n",
       "\n",
       "       SMOKE  ALCOHOL  PHYSICAL_ACTIVITY  CARDIO_DISEASE  \n",
       "0          0        0                  1               0  \n",
       "1          0        0                  1               1  \n",
       "2          0        0                  0               1  \n",
       "3          0        0                  1               1  \n",
       "4          0        0                  0               0  \n",
       "...      ...      ...                ...             ...  \n",
       "68778      1        0                  1               0  \n",
       "68779      0        0                  1               1  \n",
       "68780      0        1                  0               1  \n",
       "68781      0        0                  0               1  \n",
       "68782      0        0                  1               0  \n",
       "\n",
       "[68783 rows x 12 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Haciendo uso de la libreria pandas para leer el dataset.\n",
    "dataset = pd.read_csv('cardiovascular_diseases_dv3.csv', delimiter=';')\n",
    "\n",
    "#Imprimimos en una tabla el dataset para hacer un analisis mas claro.\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Separamos los datos\n",
    "Separamos los datos donde el 80% de los datos del dataset seran para el entrenamiento del modelo, mientras que el 20% restante del dataset sera usando para hacer las pruebas y validaciones correspondientes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  X[:,0] X[:, 1]   X[:, 2]   X[:, 3] X[:, 4] X[:, 5] X[:, 6] X[:, 7]X[:, 8]   X[:, 9]  X[:, 10]         Y\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "      50       1       173        72     120      70       1       1       0         0       1           1\n",
      "      62       2       174        52     120      80       1       1       1         0       1           1\n",
      "      46       2       156        62     115      70       1       1       0         0       1           0\n",
      "      58       1       158        90     140      90       1       1       0         0       1           1\n",
      "      62       1       156        90     160      80       3       3       0         0       1           0\n",
      "      60       1       151        44     120      80       1       2       0         0       1           0\n",
      "      40       1       156        56     120      70       1       1       0         0       1           0\n",
      "      45       1       157        43     120      80       1       1       0         0       1           0\n",
      "      56       1       167        78     130      80       3       3       0         0       1           1\n",
      "      40       2       174        82     120      80       1       1       1         0       1           0\n",
      " \n",
      "El 80% de ejemplos para entrenamiento son la cantidad de: 55026 de ejemplos\n",
      "El 20% de ejemplos para pruebas son la cantidad de: 13757 de ejemplos\n"
     ]
    }
   ],
   "source": [
    "# usamos la libreria train_test_split que nos ayudara a separar el 80% y 20% de los datos.\n",
    "train_dataset, test_dataset = train_test_split(dataset, test_size=0.2, random_state=42)\n",
    "\n",
    "#Separamos en X_test los datos, pero dropeando nuestra y que seria 'CARDIO_DISEASE'\n",
    "X_test = test_dataset.drop(['CARDIO_DISEASE'], axis=1).values\n",
    "\n",
    "#Separamos en y_test los datos, pero solo cargando la columna de 'CARDIO_DISEASE', ya que esa sera nuestra y\n",
    "y_test = test_dataset['CARDIO_DISEASE'].values\n",
    "\n",
    "# tomamos train_dataset, seleccionamos las columnas para X_train y la columna 'CARDIO_DISEASE' para y_train\n",
    "X_train = train_dataset.drop(['CARDIO_DISEASE'], axis=1).values\n",
    "y_train = train_dataset['CARDIO_DISEASE'].values\n",
    "m_train = len(y_train)\n",
    "\n",
    "\n",
    "#Imprimimos algunos datos:\n",
    "# imprimir todos las X de datos solo 10\n",
    "print('{:>8s}{:>8s}{:>10s}{:>10s}{:>8s}{:>8s}{:>8s}{:>8s}{:>6s}{:>10s}{:>10s}{:>10s}'.format(\n",
    "    'X[:,0]', 'X[:, 1]', 'X[:, 2]', 'X[:, 3]', 'X[:, 4]', 'X[:, 5]', 'X[:, 6]', 'X[:, 7]', 'X[:, 8]', 'X[:, 9]', 'X[:, 10]', 'Y'\n",
    "))\n",
    "print('-' * 110)\n",
    "\n",
    "for i in range(10):\n",
    "    print('{:8.0f}{:8.0f}{:10.0f}{:10.0f}{:8.0f}{:8.0f}{:8.0f}{:8.0f}{:8.0f}{:10.0f}{:8.0f}{:12.0f}'.format(\n",
    "        X_train[i, 0], X_train[i, 1], X_train[i, 2], X_train[i, 3], X_train[i, 4], X_train[i, 5], X_train[i, 6], X_train[i, 7], X_train[i, 8], X_train[i, 9], X_train[i, 10], y_train[i]\n",
    "    ))\n",
    "\n",
    "#mostramos la cantidad de ejemplos\n",
    "print(\" \")\n",
    "print('El 80% de ejemplos para entrenamiento son la cantidad de: {:.0f} de ejemplos'.format( len(train_dataset)))\n",
    "print('El 20% de ejemplos para pruebas son la cantidad de: {:.0f} de ejemplos'.format( len(test_dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Normalización de caracteristicas\n",
    "\n",
    "Al visualizar los datos se puede observar que las caracteristicas tienen diferentes magnitudes, por lo cual se debe transformar cada valor en una escala de valores similares, esto con el fin de que el descenso por el gradiente pueda converger mas rapidamente. Se aplica la normalizacion esto debido a que los datos de las X estan a diferentes escalas.\n",
    "\n",
    "Hacemos el uso de la siguiente funcion para normalizar los datos de las columnas X:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def  featureNormalize(X):\n",
    "    X_norm = X.copy()\n",
    "\n",
    "    #creamos un array de ceros con una longitud igual al número de columnas en el array X. La variable mu y sigma se inicializa como este array de ceros.\n",
    "    mu = np.zeros(X.shape[1])\n",
    "    sigma = np.zeros(X.shape[1])\n",
    "\n",
    "    #Creamos el promedio de cada columna de X\n",
    "    mu = np.mean(X, axis = 0)\n",
    "    sigma = np.std(X, axis = 0)\n",
    "    \n",
    "    sigma[sigma == 0] = 1\n",
    "    \n",
    "    #normalizamos los datos con la siguiente formula\n",
    "    X_norm = (X - mu) / sigma\n",
    "\n",
    "    return X_norm, mu, sigma\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Almacenando los datos normalizados en **X_norm** usando la funcion **featureNormaliza()**, normalizando los datos de X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  X[:,0] X[:, 1]   X[:, 2]   X[:, 3] X[:, 4] X[:, 5] X[:, 6] X[:, 7]X[:, 8]   X[:, 9]  X[:, 10]\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "  -0.495  -0.730     1.058    -0.146  -0.393  -1.183  -0.538  -0.396  -0.310    -0.238   0.497\n",
      "   1.281   1.370     1.180    -1.543  -0.393  -0.143  -0.538  -0.396   3.226    -0.238   0.497\n",
      "  -1.087   1.370    -1.024    -0.844  -0.692  -1.183  -0.538  -0.396  -0.310    -0.238   0.497\n",
      "   0.689  -0.730    -0.779     1.112   0.803   0.896  -0.538  -0.396  -0.310    -0.238   0.497\n",
      "   1.281  -0.730    -1.024     1.112   1.999  -0.143   2.401   3.085  -0.310    -0.238   0.497\n",
      "   0.985  -0.730    -1.636    -2.102  -0.393  -0.143  -0.538   1.345  -0.310    -0.238   0.497\n",
      "  -1.974  -0.730    -1.024    -1.263  -0.393  -1.183  -0.538  -0.396  -0.310    -0.238   0.497\n",
      "  -1.235  -0.730    -0.901    -2.172  -0.393  -0.143  -0.538  -0.396  -0.310    -0.238   0.497\n",
      "   0.393  -0.730     0.323     0.274   0.205  -0.143   2.401   3.085  -0.310    -0.238   0.497\n",
      "  -1.974   1.370     1.180     0.553  -0.393  -0.143  -0.538  -0.396   3.226    -0.238   0.497\n"
     ]
    }
   ],
   "source": [
    "X_norm, mu, sigma= featureNormalize(X_train)\n",
    "\n",
    "# imprimir todos las X_norm de datos solo 10\n",
    "print('{:>8s}{:>8s}{:>10s}{:>10s}{:>8s}{:>8s}{:>8s}{:>8s}{:>6s}{:>10s}{:>10s}'.format(\n",
    "    'X[:,0]', 'X[:, 1]', 'X[:, 2]', 'X[:, 3]', 'X[:, 4]', 'X[:, 5]', 'X[:, 6]', 'X[:, 7]', 'X[:, 8]', 'X[:, 9]', 'X[:, 10]'\n",
    "))\n",
    "print('-' * 110)\n",
    "\n",
    "for i in range(10):\n",
    "    print('{:8.3f}{:8.3f}{:10.3f}{:10.3f}{:8.3f}{:8.3f}{:8.3f}{:8.3f}{:8.3f}{:10.3f}{:8.3f}'.format(\n",
    "        X_norm[i, 0], X_norm[i, 1], X_norm[i, 2], X_norm[i, 3], X_norm[i, 4], X_norm[i, 5], X_norm[i, 6], X_norm[i, 7], X_norm[i, 8], X_norm[i, 9], X_norm[i, 10]\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Añadimos una columan de unos a la matriz de X_norm, esto para hacer complemento a Theta cero:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  X[:,0] X[:, 1]   X[:, 2]   X[:, 3] X[:, 4] X[:, 5] X[:, 6] X[:, 7]X[:, 8]   X[:, 9]  X[:, 10]  X[:, 11]\n",
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "   1.000  -0.495    -0.730     1.058  -0.146  -0.393  -1.183  -0.538  -0.396    -0.310  -0.238   0.497\n",
      "   1.000   1.281     1.370     1.180  -1.543  -0.393  -0.143  -0.538  -0.396     3.226  -0.238   0.497\n",
      "   1.000  -1.087     1.370    -1.024  -0.844  -0.692  -1.183  -0.538  -0.396    -0.310  -0.238   0.497\n",
      "   1.000   0.689    -0.730    -0.779   1.112   0.803   0.896  -0.538  -0.396    -0.310  -0.238   0.497\n",
      "   1.000   1.281    -0.730    -1.024   1.112   1.999  -0.143   2.401   3.085    -0.310  -0.238   0.497\n",
      "   1.000   0.985    -0.730    -1.636  -2.102  -0.393  -0.143  -0.538   1.345    -0.310  -0.238   0.497\n",
      "   1.000  -1.974    -0.730    -1.024  -1.263  -0.393  -1.183  -0.538  -0.396    -0.310  -0.238   0.497\n",
      "   1.000  -1.235    -0.730    -0.901  -2.172  -0.393  -0.143  -0.538  -0.396    -0.310  -0.238   0.497\n",
      "   1.000   0.393    -0.730     0.323   0.274   0.205  -0.143   2.401   3.085    -0.310  -0.238   0.497\n",
      "   1.000  -1.974     1.370     1.180   0.553  -0.393  -0.143  -0.538  -0.396     3.226  -0.238   0.497\n"
     ]
    }
   ],
   "source": [
    "X_ready = np.concatenate([np.ones((m_train, 1)), X_norm], axis=1)\n",
    "\n",
    "# print(len(X_ready[0]))\n",
    "\n",
    "# imprimir todos las X_norm de datos solo 10\n",
    "print('{:>8s}{:>8s}{:>10s}{:>10s}{:>8s}{:>8s}{:>8s}{:>8s}{:>6s}{:>10s}{:>10s}{:>10s}'.format(\n",
    "    'X[:,0]', 'X[:, 1]', 'X[:, 2]', 'X[:, 3]', 'X[:, 4]', 'X[:, 5]', 'X[:, 6]', 'X[:, 7]', 'X[:, 8]', 'X[:, 9]', 'X[:, 10]', 'X[:, 11]'\n",
    "))\n",
    "print('-' * 130)\n",
    "\n",
    "for i in range(10):\n",
    "    print('{:8.3f}{:8.3f}{:10.3f}{:10.3f}{:8.3f}{:8.3f}{:8.3f}{:8.3f}{:8.3f}{:10.3f}{:8.3f}{:8.3f}'.format(\n",
    "        X_ready[i, 0], X_ready[i, 1], X_ready[i, 2], X_ready[i, 3], X_ready[i, 4], X_ready[i, 5], X_ready[i, 6], X_ready[i, 7], X_ready[i, 8], X_ready[i, 9], X_ready[i, 10], X_ready[i, 11]\n",
    "    ))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Creacion de la funcion Sigmoide\n",
    "También conocida como la función logística, es una función matemática que toma cualquier número real como entrada y devuelve un valor en el rango de 0 a 1. Donde nuestra **Z** es nuestra hipotesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    # Calcula la sigmoide de una entrada z\n",
    "    # convierte la intrada a un arreglo numpy\n",
    "    z = np.array(z)\n",
    "\n",
    "    g = np.zeros(z.shape)\n",
    "\n",
    "    g = 1 / (1 + np.exp(-z))\n",
    "\n",
    "    return g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se calcula el valor de la sigmoide aplicando la funcion sigmoid con `z=0`, se debe obtener un resultado de 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n"
     ]
    }
   ],
   "source": [
    "print(sigmoid(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experimentando con otros valores de `z`. por ejemplo un array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.62245933 0.99752738 0.99330715]\n"
     ]
    }
   ],
   "source": [
    "z = [0.5, 6, 5]\n",
    "print(sigmoid(z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Descenso por el gradiente\n",
    "Al igual que regresion lineal se aplicara el descenso por la gradiente, con la diferencia que aqui se hara el uso de la funcion **sigmoid()**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4.1 Cálculo del costo $J(\\theta)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcularCosto(theta, X, y):\n",
    "    # Inicializar algunos valores utiles\n",
    "    m = y.size  # numero de ejemplos de entrenamiento\n",
    "\n",
    "    J = 0\n",
    "    \n",
    "    #hacemos el uso de la funcion sigmoid\n",
    "    h = sigmoid(X.dot(theta.T))\n",
    "    J = (1 / m) * np.sum(-y.dot(np.log(h)) - (1 - y).dot(np.log(1 - h)))\n",
    "\n",
    "    return J"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4.2 Descenso por el gradiente\n",
    "\n",
    "El costo $J(\\theta)$ esta parametrizado por el vector $\\theta$, no $X$ y $y$. Donde hay que minimizar el valor de $J(\\theta)$ cambiando los valores del vector $\\theta$. Una buena manera de verificar si el descenso por el gradiente esta trabajando correctamente es ver los valores de $J(\\theta)$ y verificar si estos decresen en cada paso.\n",
    "\n",
    "Creamos la funcion para calcular el descenso por la gradiente y obtener un theta y J_historico. haciendo uso de la **sigmoid()**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def descensoGradiente(theta, X, y, alpha, num_iters):\n",
    "    # Inicializa algunos valores\n",
    "    m = y.shape[0] # numero de ejemplos de entrenamiento\n",
    "\n",
    "    # realiza una copia de theta, el cual será acutalizada por el descenso por el gradiente\n",
    "    theta = theta.copy()\n",
    "    J_history = []\n",
    "\n",
    "    for i in range(num_iters):\n",
    "        h = sigmoid(X.dot(theta.T))\n",
    "        theta = theta - (alpha / m) * (h - y).dot(X)\n",
    "\n",
    "        J_history.append(calcularCosto(theta, X, y))\n",
    "    return theta, J_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se inicializan los parametros $\\theta$ con 0 y la taza de aprendizaje $\\alpha$ con 0.009."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########################################################################################################\n",
      "Los valores de theta calculados son:\n",
      "theta 1: -0.004257685920909463\n",
      "theta 2: 0.3044827570146754\n",
      "theta 3: -0.01249678210356872\n",
      "theta 4: -0.03148555570834074\n",
      "theta 5: 0.16772202914830697\n",
      "theta 6: 0.576387737779135\n",
      "theta 7: 0.3181478177267446\n",
      "theta 8: 0.2658035486972091\n",
      "theta 9: 0.010987464340882876\n",
      "theta 10: -0.037013399897440485\n",
      "theta 11: -0.034055115173726884\n",
      "theta 12: -0.07353863340382433\n",
      "########################################################################################################\n",
      "con un costo de: 0.5673536009103864 \n"
     ]
    }
   ],
   "source": [
    "#creamos un theta con 19 columnas de ceros\n",
    "theta = np.zeros(len(X_ready[0]))\n",
    "\n",
    "#numero de iteraciones sera 900 y un alpha 0.009\n",
    "num_ite = 900\n",
    "alpha = 0.009\n",
    "\n",
    "theta, J_historico = descensoGradiente(theta, X_ready, y_train, alpha, num_ite)\n",
    "\n",
    "print(\"########################################################################################################\")\n",
    "print(\"Los valores de theta calculados son:\")\n",
    "i = 0\n",
    "for tht in theta:\n",
    "    i += 1\n",
    "    print(f\"theta {i}: {tht}\")\n",
    "\n",
    "\n",
    "print(f\"########################################################################################################\")\n",
    "#mostramos el ultimo costo, este seria el mejor costo\n",
    "print(f\"con un costo de: { J_historico[-1]} \")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Grafica de la convergencia del costo\n",
    "Se utilizan los parametros finales para grafical la linea, graficamos el costo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Costo J')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkAAAAHHCAYAAABXx+fLAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/H5lhTAAAACXBIWXMAAA9hAAAPYQGoP6dpAABm4UlEQVR4nO3dd3gUVdsG8Ht3k91N752QhEBIQqihGEJTAgERBX0VFaUpzSAINpAPEJViQxQRhFeBV0EQkCIgSBPpJRA6KYQQWgqE9L57vj9CliwJkD5J9v5d117snjkz+8xOwt6ZOTMjE0IIEBERERkQudQFEBEREdU2BiAiIiIyOAxAREREZHAYgIiIiMjgMAARERGRwWEAIiIiIoPDAEREREQGhwGIiIiIDA4DEBERERkcBiCih9i+fTvatGkDtVoNmUyG1NRUDBs2DJ6enlKXBgDVXsvHH38MmUxWbcsj6dXWz2uPHj3Qo0ePSs3r6emJYcOGVWs9ROXBAET1wpUrVzBu3Dj4+PjA1NQUpqam8Pf3R1hYGM6cOVPt73fnzh289NJLMDExwcKFC/HLL7/AzMys2t+HiOqe7OxsfPzxx/jnn3+kLoVqkJHUBRA9zpYtWzBo0CAYGRlh8ODBaN26NeRyOS5duoQ//vgDixYtwpUrV+Dh4VFt73n8+HFkZGTg008/RUhIiK596dKl0Gq11fY+RDWJP6+Vk52djZkzZwJApfdsUd3HAER12uXLl/Hyyy/Dw8MDu3fvhouLi970zz//HD/88APk8kfvzMzKyqrQHpykpCQAgLW1tV67sbFxuZdBDVd2djZMTU2lLuOx+PNK9HA8BEZ12hdffIGsrCwsW7asVPgBACMjI4wfPx7u7u66tmHDhsHc3ByXL1/G008/DQsLCwwePBgAsH//frz44oto3LgxVCoV3N3dMXHiROTk5Ojm79GjB4YOHQoA6NChA2QymW6MQlljKrRaLb799lu0bNkSarUaDg4O6NOnD06cOKHrs2zZMjz11FNwdHSESqWCv78/Fi1aVO7PYePGjQgICIBarUZAQAA2bNhQZj+tVov58+ejRYsWUKvVcHJywujRo3H37t1yv1dJVa370qVLeOmll+Dg4AATExM0b94cU6dO1etz6tQp9O3bF5aWljA3N0fPnj1x5MgRvT7Lly+HTCbDwYMHMWnSJDg4OMDMzAwDBw5EcnKyrt8zzzyDJk2alFlLUFAQ2rdvr9f266+/IjAwECYmJrC1tcXLL7+Ma9eu6fXp0aMHAgICEB4ejm7dusHU1BQfffQRgKJDpa+//josLS1hbW2NoUOH4vTp05DJZFi+fHmpz+I///kPbG1toVar0b59e2zevLlS61nsr7/+Qvfu3WFhYQFLS0t06NABq1at0k0v6+f1q6++QufOnWFnZwcTExMEBgZi3bp1ZX5mZVmyZAm8vb1hYmKCjh07Yv/+/WX2y8vLw4wZM9C0aVPd79oHH3yAvLy8cr9XSeX5PSssLMSnn34Kb29vqFQqeHp64qOPPir1nidOnEBoaCjs7e1hYmICLy8vjBgxAgAQFxcHBwcHAMDMmTMhk8kgk8nw8ccf6+bfs2cPunbtCjMzM1hbW+O5557DxYsXK7VeJB3uAaI6bcuWLWjatCk6depUofkKCwsRGhqKLl264KuvvtL9tb527VpkZ2dj7NixsLOzw7Fjx7BgwQJcv34da9euBQBMnToVzZs3x5IlS/DJJ5/Ay8sL3t7eD32vN954A8uXL0ffvn3x5ptvorCwEPv378eRI0d0X7iLFi1CixYt8Oyzz8LIyAh//vkn3nrrLWi1WoSFhT1yXf7++2+88MIL8Pf3x5w5c3Dnzh0MHz4cjRo1KtV39OjRWL58OYYPH47x48fjypUr+P7773Hq1CkcPHiwwnsEqlL3mTNn0LVrVxgbG2PUqFHw9PTE5cuX8eeff2LWrFkAgPPnz6Nr166wtLTEBx98AGNjY/z444/o0aMH9u3bV2q7v/3227CxscGMGTMQFxeH+fPnY9y4cVizZg0AYNCgQRgyZAiOHz+ODh066Oa7evUqjhw5gi+//FLXNmvWLEybNg0vvfQS3nzzTSQnJ2PBggXo1q0bTp06pbf3786dO+jbty9efvllvPbaa3BycoJWq0X//v1x7NgxjB07Fr6+vti0aZMuPJd0/vx5BAcHw83NDZMnT4aZmRl+//13DBgwAOvXr8fAgQMrtJ5AUVgaMWIEWrRogSlTpsDa2hqnTp3C9u3b8eqrrz50u3z77bd49tlnMXjwYOTn52P16tV48cUXsWXLFvTr1++R2/Snn37C6NGj0blzZ7zzzjuIjY3Fs88+C1tbW70/QrRaLZ599lkcOHAAo0aNgp+fH86ePYtvvvkGUVFR2Lhx4yPfpyzl+T178803sWLFCvznP//Bu+++i6NHj2LOnDm4ePGi7o+GpKQk9O7dGw4ODpg8eTKsra0RFxeHP/74AwDg4OCARYsWYezYsRg4cCCef/55AECrVq0AALt27ULfvn3RpEkTfPzxx8jJycGCBQsQHByMkydP1pmTJKgcBFEdlZaWJgCIAQMGlJp29+5dkZycrHtkZ2frpg0dOlQAEJMnTy41X8l+xebMmSNkMpm4evWqrm3ZsmUCgDh+/Lhe36FDhwoPDw/d6z179ggAYvz48aWWq9VqH/m+oaGhokmTJqXaH9SmTRvh4uIiUlNTdW1///23AKBXy/79+wUAsXLlSr35t2/fXmb7g2bMmCEe/C+hKnV369ZNWFhY6H2uQuh/LgMGDBBKpVJcvnxZ13bz5k1hYWEhunXrpmsr3h4hISF680+cOFEoFArdZ5OWliZUKpV499139d7ziy++0NvGcXFxQqFQiFmzZun1O3v2rDAyMtJr7969uwAgFi9erNd3/fr1AoCYP3++rk2j0YinnnpKABDLli3Ttffs2VO0bNlS5Obm6n0OnTt3Fs2aNavweqampgoLCwvRqVMnkZOT89DP98GfVyFKb9P8/HwREBAgnnrqKfEo+fn5wtHRUbRp00bk5eXp2pcsWSIAiO7du+vafvnlFyGXy8X+/fv1lrF48WIBQBw8eFDX5uHhIYYOHfrI9y7P71lERIQAIN5880296e+9954AIPbs2SOEEGLDhg1l/m6XlJycLACIGTNmlJrWpk0b4ejoKO7cuaNrO336tJDL5WLIkCGPXA+qW3gIjOqs9PR0AIC5uXmpaT169ICDg4PusXDhwlJ9xo4dW6rNxMRE9zwrKwu3b99G586dIYTAqVOnKlzj+vXrIZPJMGPGjFLTSp5SXvJ909LScPv2bXTv3h2xsbFIS0t76PJv3bqFiIgIDB06FFZWVrr2Xr16wd/fX6/v2rVrYWVlhV69euH27du6R2BgIMzNzbF3794Kr19l605OTsa///6LESNGoHHjxnrTij8XjUaDv//+GwMGDNA7bOXi4oJXX30VBw4c0P0MFBs1apTe59q1a1doNBpcvXoVAGBpaYm+ffvi999/hxBC12/NmjV44okndLX88ccf0Gq1eOmll/Q+K2dnZzRr1qzUZ6VSqTB8+HC9tu3bt8PY2BgjR47Utcnl8lJ7xlJSUrBnzx689NJLyMjI0L3XnTt3EBoaiujoaNy4caNC67lz505kZGRg8uTJUKvVZX6+D1Nym969exdpaWno2rUrTp48+cj5Tpw4gaSkJIwZMwZKpVLXPmzYML2fTaDoZ9HPzw++vr56n+9TTz0FABX+WSzP79m2bdsAAJMmTdKb/u677wIAtm7dCuD+uL4tW7agoKCgQnUU/z4OGzYMtra2uvZWrVqhV69euhqofuAhMKqzLCwsAACZmZmlpv3444/IyMhAYmIiXnvttVLTjYyMyjxEFB8fj+nTp2Pz5s2lxsU86gv9YS5fvgxXV1e9/wzLcvDgQcyYMQOHDx9GdnZ2qfd98AukWPEXXrNmzUpNa968ud6XVnR0NNLS0uDo6FjmsooHdldEZeuOjY0FAAQEBDx02cnJycjOzkbz5s1LTfPz84NWq8W1a9fQokULXfuDYcrGxgYA9LbloEGDsHHjRhw+fBidO3fG5cuXER4ejvnz5+v6REdHQwhR5ucKlB487ObmpvelDxRtGxcXl1KDoZs2bar3OiYmBkIITJs2DdOmTSvz/ZKSkuDm5lbu9bx8+TKAR3++D7NlyxZ89tlniIiI0Bsb87jg9LCfRWNj41LjrqKjo3Hx4kXdWJoHVfRnsTy/Z1evXoVcLi/1+Ts7O8Pa2lpXf/fu3fHCCy9g5syZ+Oabb9CjRw8MGDAAr776KlQq1SPrKF7Gw35md+zYUeETLkg6DEBUZ1lZWcHFxQXnzp0rNa14bEhcXFyZ86pUqlJnhmk0GvTq1QspKSn48MMP4evrCzMzM9y4cQPDhg2rsdOFL1++jJ49e8LX1xfz5s2Du7s7lEoltm3bhm+++aba3ler1cLR0RErV64sc/rDvoweprbqrgiFQlFme8m9Pf3794epqSl+//13dO7cGb///jvkcjlefPFFXR+tVguZTIa//vqrzGU+uNex5F6Tiir+nN577z2EhoaW2efBL+3yrGdl7N+/H88++yy6deuGH374AS4uLjA2NsayZcv0Bk9XlVarRcuWLTFv3rwyp5ccL1TdHhfkZDIZ1q1bhyNHjuDPP//Ejh07MGLECHz99dc4cuRImXucqWFiAKI6rV+/fvjvf/+LY8eOoWPHjlVa1tmzZxEVFYUVK1ZgyJAhuvadO3dWepne3t7YsWMHUlJSHvrX6Z9//om8vDxs3rxZ7y/78hwGKL62UXR0dKlpkZGRpWrZtWsXgoODq/SFXawqdRfvESgrvBZzcHCAqalpqfUAis6YksvllfqiNDMzwzPPPIO1a9di3rx5WLNmDbp27QpXV1ddH29vbwgh4OXlBR8fnwq/B1C0bfbu3VvqlPiYmBi9fsWfhbGxsd41paqieFD+uXPnSoWnR1m/fj3UajV27Niht7dj2bJlj5235M9i8aEsACgoKMCVK1fQunVrvfpOnz6Nnj17VsvVxcvze+bh4QGtVovo6Gj4+fnp2hMTE5GamlrqOmFPPPEEnnjiCcyaNQurVq3C4MGDsXr1arz55psPrbl4GQ/7mbW3t+fen3qEY4CoTvvggw9gamqKESNGIDExsdT0ivxFXPxXdcl5hBD49ttvK13fCy+8ACGE7qJpZdVW1vumpaWV60vHxcUFbdq0wYoVK/QO0e3cuRMXLlzQ6/vSSy9Bo9Hg008/LbWcwsJCpKamlmudilWlbgcHB3Tr1g0///wz4uPj9aaV/Fx69+6NTZs26e3JS0xMxKpVq9ClSxdYWlpWqOZigwYNws2bN/Hf//4Xp0+fxqBBg/SmP//881AoFJg5c2apnyEhBO7cufPY9wgNDUVBQQGWLl2qa9NqtaXGozk6OqJHjx748ccfcevWrVLLKev09sfp3bs3LCwsMGfOHOTm5paq/2EUCgVkMhk0Go2uLS4urlxnZbVv3x4ODg5YvHgx8vPzde3Lly8v9bP10ksv4caNG3qfTbGcnBxkZWU99v1KKs/v2dNPPw0Aeoc6Aej2QhWf4Xb37t1Sn1GbNm0AQHdIsDjQPrheJX8fS047d+4c/v77b10NVD9wDxDVac2aNcOqVavwyiuvoHnz5rorQQshcOXKFaxatQpyubzM8T4P8vX1hbe3N9577z3cuHEDlpaWWL9+faWvkQMATz75JF5//XV89913iI6ORp8+faDVarF//348+eSTGDduHHr37g2lUon+/ftj9OjRyMzMxNKlS+Ho6FjmF+KD5syZg379+qFLly4YMWIEUlJSsGDBArRo0UJvfFT37t0xevRozJkzBxEREejduzeMjY0RHR2NtWvX4ttvv8V//vOfcq9bVev+7rvv0KVLF7Rr1w6jRo2Cl5cX4uLisHXrVkRERAAAPvvsM+zcuRNdunTBW2+9BSMjI/z444/Iy8vDF198Ue5aH1R8/af33nsPCoUCL7zwgt50b29vfPbZZ5gyZQri4uIwYMAAWFhY4MqVK9iwYQNGjRqF995775HvMWDAAHTs2BHvvvsuYmJi4Ovri82bNyMlJQWA/qGYhQsXokuXLmjZsiVGjhyJJk2aIDExEYcPH8b169dx+vTpCq2fpaUlvvnmG7z55pvo0KEDXn31VdjY2OD06dPIzs7GihUrypyvX79+mDdvHvr06YNXX30VSUlJWLhwIZo2bfrYW8oYGxvjs88+w+jRo/HUU09h0KBBuHLlCpYtW1ZqDNDrr7+O33//HWPGjMHevXsRHBwMjUaDS5cu4ffff8eOHTtKXZPpUcrze9a6dWsMHToUS5YsQWpqKrp3745jx45hxYoVGDBgAJ588kkAwIoVK/DDDz9g4MCB8Pb2RkZGBpYuXQpLS0tdgDExMYG/vz/WrFkDHx8f2NraIiAgAAEBAfjyyy/Rt29fBAUF4Y033tCdBm9lZaV3rSCqB2rzlDOiyoqJiRFjx44VTZs2FWq1WpiYmAhfX18xZswYERERodd36NChwszMrMzlXLhwQYSEhAhzc3Nhb28vRo4cKU6fPl3qtOXyngYvhBCFhYXiyy+/FL6+vkKpVAoHBwfRt29fER4eruuzefNm0apVK6FWq4Wnp6f4/PPPxc8//ywAiCtXrjx2/devXy/8/PyESqUS/v7+4o8//iizFiGKTksODAwUJiYmwsLCQrRs2VJ88MEH4ubNm498j7JOg69q3efOnRMDBw4U1tbWQq1Wi+bNm4tp06bp9Tl58qQIDQ0V5ubmwtTUVDz55JPi0KFDen0etj327t0rAIi9e/eWeu/BgwfrTil/mPXr14suXboIMzMzYWZmJnx9fUVYWJiIjIzU9enevbto0aJFmfMnJyeLV199VVhYWAgrKysxbNgwcfDgQQFArF69Wq/v5cuXxZAhQ4Szs7MwNjYWbm5u4plnnhHr1q2r9Hpu3rxZdO7cWZiYmAhLS0vRsWNH8dtvv+mml/Uz8tNPP4lmzZoJlUolfH19xbJly8rc9g/zww8/CC8vL6FSqUT79u3Fv//+K7p37653GrwQRafNf/7556JFixZCpVIJGxsbERgYKGbOnCnS0tJ0/cpzGrwQ5fs9KygoEDNnzhReXl7C2NhYuLu7iylTpuhdfuDkyZPilVdeEY0bNxYqlUo4OjqKZ555Rpw4cULv/Q4dOiQCAwOFUqksdUr8rl27RHBwsO5z79+/v7hw4UK5Pj+qO2RCVHFUHRER6WzcuBEDBw7EgQMHEBwcLHU5RPQQDEBERJWUk5OjN+Bco9Ggd+/eOHHiBBISEqplMDoR1QyOASIiqqS3334bOTk5CAoKQl5eHv744w8cOnQIs2fPZvghquO4B4iIqJJWrVqFr7/+GjExMcjNzUXTpk0xduxYjBs3TurSiOgxGICIiIjI4PA6QERERGRwGICIiIjI4HAQdBm0Wi1u3rwJCwuLarmMOxEREdU8IQQyMjLg6upa6n6QD2IAKsPNmzdr9GZ9REREVHOuXbv22DsEMACVwcLCAkDRB1jZexERERFR7UpPT4e7u7vue/xRGIDKUHzYy9LSkgGIiIioninP8BUOgiYiIiKDwwBEREREBocBiIiIiAwOAxAREREZHAYgIiIiMjgMQERERGRwGICIiIjI4DAAERERkcFhACIiIiKDwwBEREREBocBiIiIiAwOAxAREREZHN4MtRYdib2D09dSkZyRh/97xl/qcoiIiAwWA1At+nTLBZy/mQ65DJjU2wemSn78REREUuAhsFrU0s0KAKAVwMVb6RJXQ0REZLgYgGpRi3sBCADOXk+TsBIiIiLDxgBUi1qWDEA3uAeIiIhIKgxAtcjX2QIKuQwAcP4m9wARERFJhQGoFqmNFWjmaA4AiE7KRG6BRuKKiIiIDBMDUC0LuHcYTKMVHAhNREQkEQagWlZyHNC5GzwMRkREJAUGoFoW4Gape36OA6GJiIgkwQBUy/xdrHBvHDTOcg8QERGRJBiAapmJUoGm9wZCRyVmIK+QA6GJiIhqGwOQBAJci8YBFWoFIhMyJK6GiIjI8DAASSBAbyA0xwERERHVNgYgCQToXRGa44CIiIhqGwOQBPxdLSG7NxCaV4QmIiKqfQxAEjBXGcHL3gwAcOlWBvILtRJXREREZFgYgCRSfEHEfI0W0UkcCE1ERFSbGIAkUnwmGMArQhMREdU2BiCJcCA0ERGRdBiAJNLC7f5A6DPXGYCIiIhqEwOQRCzVxvB2KLoi9MVb6cgt4BWhiYiIagsDkIRaN7IGABRoBC7e4gURiYiIagsDkITauN8fB3T6Wqp0hRARERkYBiAJtXa31j0/zXFAREREtYYBSEK+zpZQKoo2AfcAERER1R4GIAkpjeTwd7UEAMTezkJadoHEFRERERkGBiCJtSlxGOzMjVTJ6iAiIjIkDEASa82B0ERERLWOAUhixafCA0DENQ6EJiIiqg2SB6CFCxfC09MTarUanTp1wrFjxx7ZPzU1FWFhYXBxcYFKpYKPjw+2bdumm67RaDBt2jR4eXnBxMQE3t7e+PTTTyGEqOlVqRRPOzNYqo0AABHXUutsnURERA2JkZRvvmbNGkyaNAmLFy9Gp06dMH/+fISGhiIyMhKOjo6l+ufn56NXr15wdHTEunXr4ObmhqtXr8La2lrX5/PPP8eiRYuwYsUKtGjRAidOnMDw4cNhZWWF8ePH1+LalY9cLkNrd2vsj76N25l5uJWWC1drE6nLIiIiatAkDUDz5s3DyJEjMXz4cADA4sWLsXXrVvz888+YPHlyqf4///wzUlJScOjQIRgbGwMAPD099focOnQIzz33HPr166eb/ttvvz12z5KUWjcqCkBA0TggBiAiIqKaJdkhsPz8fISHhyMkJOR+MXI5QkJCcPjw4TLn2bx5M4KCghAWFgYnJycEBARg9uzZ0Gju30erc+fO2L17N6KiogAAp0+fxoEDB9C3b9+aXaEqKHlBxIjrqZLVQUREZCgk2wN0+/ZtaDQaODk56bU7OTnh0qVLZc4TGxuLPXv2YPDgwdi2bRtiYmLw1ltvoaCgADNmzAAATJ48Genp6fD19YVCoYBGo8GsWbMwePDgh9aSl5eHvLw83ev09Nq9L1frRvfPBDvDgdBEREQ1TtJDYBWl1Wrh6OiIJUuWQKFQIDAwEDdu3MCXX36pC0C///47Vq5ciVWrVqFFixaIiIjAO++8A1dXVwwdOrTM5c6ZMwczZ86szVXR42iphouVGrfScnH2Rho0WgGFXCZZPURERA2dZIfA7O3toVAokJiYqNeemJgIZ2fnMudxcXGBj48PFAqFrs3Pzw8JCQnIz88HALz//vuYPHkyXn75ZbRs2RKvv/46Jk6ciDlz5jy0lilTpiAtLU33uHbtWjWsYcUUnw6fmVeI6KSMWn9/IiIiQyJZAFIqlQgMDMTu3bt1bVqtFrt370ZQUFCZ8wQHByMmJgZarVbXFhUVBRcXFyiVSgBAdnY25HL91VIoFHrzPEilUsHS0lLvUdvaeVjrnp+8mlrr709ERGRIJL0O0KRJk7B06VKsWLECFy9exNixY5GVlaU7K2zIkCGYMmWKrv/YsWORkpKCCRMmICoqClu3bsXs2bMRFham69O/f3/MmjULW7duRVxcHDZs2IB58+Zh4MCBtb5+FRHoYaN7fjL+roSVEBERNXySjgEaNGgQkpOTMX36dCQkJKBNmzbYvn27bmB0fHy83t4cd3d37NixAxMnTkSrVq3g5uaGCRMm4MMPP9T1WbBgAaZNm4a33noLSUlJcHV1xejRozF9+vRaX7+KaOFqBWOFDAUagZNXGYCIiIhqkkzw0sOlpKenw8rKCmlpabV6OGzgDwdxKj4VAHByWi/Ymilr7b2JiIjqu4p8f0t+Kwy6r13j+4fBTvEwGBERUY1hAKpDOA6IiIiodjAA1SEl9wCFcxwQERFRjWEAqkOcrdRwu3cfsNPX0lCoefip+0RERFR5DEB1TNvG1gCAnAINLiXwgohEREQ1gQGojuE4ICIioprHAFTHcBwQERFRzWMAqmP8XS2hNi7aLAxARERENYMBqI4xVsjRys0aAHD9bg6S0nOlLYiIiKgBYgCqg9pxHBAREVGNYgCqg0oOhOZhMCIiourHAFQHtbt3KjwAHI9jACIiIqpuDEB1kJ25Ct4OZgCAczfSkJ1fKHFFREREDQsDUB3V0csWAFCoFYi4d4d4IiIiqh4MQHVUcQACgKNXUiSshIiIqOFhAKqjOnjeD0DH4xiAiIiIqhMDUB3VyMYUrlZqAEWnwucX8saoRERE1YUBqA4rPgyWW6DFuZtpEldDRETUcDAA1WEdSowDOs5xQERERNWGAagO68hxQERERDWCAagOa+poDlszJYCiCyJqtULiioiIiBoGBqA6TCaTof2922Kk5RQgKilD4oqIiIgaBgagOq4jxwERERFVOwagOq5kADrG+4IRERFVCwagOs7fxRJmSgUA4NiVOxCC44CIiIiqigGojjNSyNHu3jigxPQ8xKdkS1wRERFR/ccAVA880cRO9/zw5TsSVkJERNQwMADVA3oBKJYBiIiIqKoYgOqBVo2sYHpvHNChyxwHREREVFUMQPWAsUKuOxssOSMPl5OzJK6IiIiofmMAqieC9MYB3ZawEiIiovqPAaie6Oxtr3vOcUBERERVwwBUT/i7WsJSbQQAOBKbwvuCERERVQEDUD2hkMvQ0avoMFhKVj4iE3lfMCIiospiAKpHOnvzekBERETVgQGoHgkqEYAOMQARERFVGgNQPdLcyQI2psYAgKNX7kDDcUBERESVwgBUj8jlMt1eoIzcQpy/mSZxRURERPUTA1A9E8T7ghEREVUZA1A9E1TiekAHYnhBRCIiospgAKpnvB3M4GypBgAcu5KC3AKNxBURERHVPwxA9YxMJkPXZkV7gfIKtQi/elfiioiIiOofBqB6qKuPg+75v9HJElZCRERUP0kegBYuXAhPT0+o1Wp06tQJx44de2T/1NRUhIWFwcXFBSqVCj4+Pti2bZtenxs3buC1116DnZ0dTExM0LJlS5w4caImV6NWBZe4HtD+KI4DIiIiqigjKd98zZo1mDRpEhYvXoxOnTph/vz5CA0NRWRkJBwdHUv1z8/PR69eveDo6Ih169bBzc0NV69ehbW1ta7P3bt3ERwcjCeffBJ//fUXHBwcEB0dDRsbm1pcs5plZ65CgJslzt1Ix4Vb6bidmQd7c5XUZREREdUbkgagefPmYeTIkRg+fDgAYPHixdi6dSt+/vlnTJ48uVT/n3/+GSkpKTh06BCMjYsuCOjp6anX5/PPP4e7uzuWLVuma/Py8qq5lZBIl6YOOHcjHQBwMOY2nmvjJnFFRERE9Ydkh8Dy8/MRHh6OkJCQ+8XI5QgJCcHhw4fLnGfz5s0ICgpCWFgYnJycEBAQgNmzZ0Oj0ej1ad++PV588UU4Ojqibdu2WLp0aY2vT23r1uz+6fD/8jAYERFRhUgWgG7fvg2NRgMnJye9dicnJyQkJJQ5T2xsLNatWweNRoNt27Zh2rRp+Prrr/HZZ5/p9Vm0aBGaNWuGHTt2YOzYsRg/fjxWrFjx0Fry8vKQnp6u96jrAj1toDYu2nwHYpIhBG+LQUREVF6SD4KuCK1WC0dHRyxZsgSBgYEYNGgQpk6disWLF+v1adeuHWbPno22bdti1KhRGDlypF6fB82ZMwdWVla6h7u7e22sTpWojBTo5FU0GDoxPQ/RSZkSV0RERFR/SBaA7O3toVAokJiYqNeemJgIZ2fnMudxcXGBj48PFAqFrs3Pzw8JCQnIz8/X9fH399ebz8/PD/Hx8Q+tZcqUKUhLS9M9rl27VtnVqlVd9Q6D8XR4IiKi8pIsACmVSgQGBmL37t26Nq1Wi927dyMoKKjMeYKDgxETEwOtVqtri4qKgouLC5RKpa5PZGSk3nxRUVHw8PB4aC0qlQqWlpZ6j/qgW4nrAfG2GEREROUn6SGwSZMmYenSpVixYgUuXryIsWPHIisrS3dW2JAhQzBlyhRd/7FjxyIlJQUTJkxAVFQUtm7ditmzZyMsLEzXZ+LEiThy5Ahmz56NmJgYrFq1CkuWLNHr01A0czSHk2XR6e9HYu8gr5C3xSAiIioPSU+DHzRoEJKTkzF9+nQkJCSgTZs22L59u25gdHx8POTy+xnN3d0dO3bswMSJE9GqVSu4ublhwoQJ+PDDD3V9OnTogA0bNmDKlCn45JNP4OXlhfnz52Pw4MG1vn41TSaToUtTB6w/eR25BVocv3IXXUocFiMiIqKyyQRPHyolPT0dVlZWSEtLq/OHw/48fRNv/3YKAPBGFy9Me8b/MXMQERE1TBX5/q5XZ4FRad2aOUAhlwEA9kYmSVwNERFR/cAAVM9ZmRojsHHRbT5ik7Nw9U6WxBURERHVfQxADUAP3/tng/0TydPhiYiIHocBqAF4svn9G8fuucTDYERERI/DANQA+DpbwNlSDQA4HHsHOfk8HZ6IiOhRGIAaAJlMhifvHQbLL9TicCwvikhERPQoDEANRMnDYHsvcRwQERHRozAANRDBTe1hrLh/Ojwv70RERPRwDEANhJnKSHd3+Ot3c3A5mXeHJyIiehgGoAakR/P7p8PzMBgREdHDMQA1IE/63h8HtOtiooSVEBER1W0MQA1IE3szeNmbAQCOx6Xgbla+xBURERHVTQxADYhMJkMvfycAgFbwoohEREQPwwDUwBQHIADYeYGHwYiIiMrCANTAtGtsAzszJQDg3+hk5BbwqtBEREQPYgBqYBRyGZ66Nxg6O1+DQ5d5VWgiIqIHMQA1QDwMRkRE9GgMQA1Q12YOUBsXbdpdF5Og1fKq0ERERCUxADVAJkoFujQtuihickYeIq6nSlsQERFRHcMA1ED18r9/UUQeBiMiItLHANRAPeXrBFnRvVEZgIiIiB7AANRAOVio0K6xDQAgJikTsbw5KhERkQ4DUAMW2uL+2WB/nUuQsBIiIqK6hQGoAesb4KJ7/te5WxJWQkREVLcwADVg7ramaOlmBQA4dyMd8XeyJa6IiIiobmAAauD6tnTWPedeICIioiIMQA1cycNg2zgOiIiICAADUIPnZW8GPxdLAMDpa6m4kZojcUVERETSYwAyAE8H3D8Mtp17gYiIiBiADEHfliXOBjvLcUBEREQMQAagqaM5fJzMAQAnrt5FQlquxBURERFJiwHIQJQcDL3jPA+DERGRYWMAMhBPlzgMtuXMTQkrISIikh4DkIHwcTJHU8eiw2DH4+7ybDAiIjJoDEAGQiaT4dnWrrrXW05zLxARERkuBiADUjIAbYpgACIiIsPFAGRAPO3N0LpR0b3BLtxKR0xSpsQVERERSYMByMD0L7EXaDMPgxERkYFiADIw/Vu7QiYrev7n6ZsQQkhbEBERkQQYgAyMk6UaT3jZAQCu3M7CuRvpEldERERU+xiADNCzbUoOhr4hYSVERETSYAAyQH0DnGGsKDoOtuXMLWi1PAxGRESGhQHIAFmbKtGtmQMAICE9F0di70hcERERUe2qEwFo4cKF8PT0hFqtRqdOnXDs2LFH9k9NTUVYWBhcXFygUqng4+ODbdu2ldl37ty5kMlkeOedd2qg8vprQFs33fN1J69LWAkREVHtkzwArVmzBpMmTcKMGTNw8uRJtG7dGqGhoUhKSiqzf35+Pnr16oW4uDisW7cOkZGRWLp0Kdzc3Er1PX78OH788Ue0atWqplej3unl7wQLtREAYPu5BGTlFUpcERERUe2RPADNmzcPI0eOxPDhw+Hv74/FixfD1NQUP//8c5n9f/75Z6SkpGDjxo0IDg6Gp6cnunfvjtatW+v1y8zMxODBg7F06VLY2NjUxqrUK2pjBZ5pVTQYOjtfg7/O8Q7xRERkOCQNQPn5+QgPD0dISIiuTS6XIyQkBIcPHy5zns2bNyMoKAhhYWFwcnJCQEAAZs+eDY1Go9cvLCwM/fr101v2w+Tl5SE9PV3vYQj+E9hI93x9OA+DERGR4ZA0AN2+fRsajQZOTk567U5OTkhIKHuPRGxsLNatWweNRoNt27Zh2rRp+Prrr/HZZ5/p+qxevRonT57EnDlzylXHnDlzYGVlpXu4u7tXfqXqkXaNreFlbwYAOBx7B9dSsiWuiIiIqHZIfgisorRaLRwdHbFkyRIEBgZi0KBBmDp1KhYvXgwAuHbtGiZMmICVK1dCrVaXa5lTpkxBWlqa7nHt2rWaXIU6QyaT4YV298dObTjFawIREZFhkDQA2dvbQ6FQIDExUa89MTERzs7OZc7j4uICHx8fKBQKXZufnx8SEhJ0h9SSkpLQrl07GBkZwcjICPv27cN3330HIyOjUofKAEClUsHS0lLvYSgGtmukuzXGHyev89YYRERkECQNQEqlEoGBgdi9e7euTavVYvfu3QgKCipznuDgYMTExECr1eraoqKi4OLiAqVSiZ49e+Ls2bOIiIjQPdq3b4/BgwcjIiJCLzgR4GZtgqAmRbfGiLuTjfCrdyWuiIiIqOZJfghs0qRJWLp0KVasWIGLFy9i7NixyMrKwvDhwwEAQ4YMwZQpU3T9x44di5SUFEyYMAFRUVHYunUrZs+ejbCwMACAhYUFAgIC9B5mZmaws7NDQECAJOtY15UcDL2Og6GJiMgAGEldwKBBg5CcnIzp06cjISEBbdq0wfbt23UDo+Pj4yGX389p7u7u2LFjByZOnIhWrVrBzc0NEyZMwIcffijVKtR7fQKcMW3jOWTla7D1zC3M6N8CJkruKSMiooZLJso56OO77757bB8jIyM4OzujS5cucHR0rHJxUklPT4eVlRXS0tIMZjzQe2tP6/b+zHupNZ5v1+gxcxAREdUtFfn+LvceoG+++eaxfbRaLe7cuQOtVotff/0Vzz//fHkXTxJ7uYO7LgD9diyeAYiIiBq0cgegK1eulKufVqvF3LlzMXXqVAageiTQwwbNHM0RnZSJ43F3EZ2YgWZOFlKXRUREVCOqfRC0XC7H0KFDcfv27epeNNUgmUyGlzs21r1efdwwroVERESGqUbOAnNzc0NycnJNLJpq0PNt3aA0KvqRWH/yOnILSl8ziYiIqCGQ/DR4qjtszJR4OqDoApSp2QXYcZ43SCUiooaJAYj0vFLiMNiqo/ESVkJERFRzGIBIT0cvWzRxKLpB6tErKbicnClxRURERNWvUhdC1Gg02LhxIy5evAgAaNGiBZ599lneZqIBkMlkeLVjY3y2tWjbrj4Wj6n9/CWuioiIqHpVeA9QTEwM/P39MWTIEPzxxx/4448/8Nprr6FFixa4fPlyTdRItez5do2gVBT9aKwLv468Qg6GJiKihqXCAWj8+PFo0qQJrl27hpMnT+LkyZOIj4+Hl5cXxo8fXxM1Ui2zNVOiz73B0HezC7Dt7C2JKyIiIqpeFQ5A+/btwxdffAFbW1tdm52dHebOnYt9+/ZVa3Ekndee8NA9X37oqoSVEBERVb8KByCVSoWMjIxS7ZmZmVAqldVSFEmvg6cN/FyK7qNy+loqIq6lSlsQERFRNapwAHrmmWcwatQoHD16FEIICCFw5MgRjBkzBs8++2xN1EgSkMlkGNb5/l6gFYfipCuGiIiomlU4AH333Xfw9vZGUFAQ1Go11Go1goOD0bRpU8yfP78GSiSpPNfGDdamxgCALWduIjkjT+KKiIiIqkeFT4O3trbGpk2bEBMTozsN3s/PD02bNq324khaamMFBnVwx4/7YlGgEfjtWDzG92wmdVlERERVVuE9QJ988gmys7PRtGlT9O/fH/3790fTpk2Rk5ODTz75pCZqJAm9/oQH5LKi5yuPXkWBRittQURERNWgwgFo5syZyMwsfXXg7OxszJw5s1qKorqjkY0pQvycAACJ6XnYfo73ByMiovqvwgFICAGZTFaq/fTp03qnxlPDMayzp+75cg6GJiKiBqDcY4BsbGwgk8kgk8ng4+OjF4I0Gg0yMzMxZsyYGimSpBXkbQcfJ3NEJWYi/OpdnLmeilaNrKUui4iIqNLKHYDmz58PIQRGjBiBmTNnwsrKSjdNqVTC09MTQUFBNVIkSavolHgvfLThLABg6f4rWPBKW4mrIiIiqjyZEEJUZIZ9+/YhODgYRkaVuo9qvZCeng4rKyukpaXB0tJS6nLqhNwCDYLn7sGdrHwo5DL8814PuNuaSl0WERGRTkW+vys8BsjCwkJ3+jsAbNq0CQMGDMBHH32E/Pz8ildL9YLaWIEhQZ4AAI1W4OeDV6QtiIiIqAoqHIBGjx6NqKgoAEBsbCwGDRoEU1NTrF27Fh988EG1F0h1x+tBHlAbF/3IrDl+DWnZBRJXREREVDkVDkBRUVFo06YNAGDt2rXo3r07Vq1aheXLl2P9+vXVXR/VIbZmSrwY6A4AyM7X4NejvEkqERHVT5U6DV6rLboY3q5du/D0008DANzd3XH79u3qrY7qnDe7eqH4BMDlh+KQV6iRtiAiIqJKqHAAat++PT777DP88ssv2LdvH/r16wcAuHLlCpycnKq9QKpbPOzM0KeFMwAgOSMPm07dlLgiIiKiiqtwAJo/fz5OnjyJcePGYerUqbp7gK1btw6dO3eu9gKp7hnVrYnu+ZL9sdBqK3QiIRERkeQqfBr8w+Tm5kKhUMDY2Lg6Ficpngb/eC8uPoTjcXcBAEuHtEcvf+79IyIiaVXk+7vSF/MJDw/XnQ7v7++Pdu3aVXZRVA+N6e6N43EnAADf74lGiJ9jmbdIISIiqosqHICSkpIwaNAg7Nu3D9bW1gCA1NRUPPnkk1i9ejUcHByqu0aqg57ydYSfiyUu3krH6etp+Df6Nrr7cNsTEVH9UOExQG+//TYyMzNx/vx5pKSkICUlBefOnUN6ejrGjx9fEzVSHSSTyfD2U011rxfsjkY1HU0lIiKqcRUOQNu3b8cPP/wAPz8/XZu/vz8WLlyIv/76q1qLo7qtTwtnNHU0BwCcuHoXR2JTJK6IiIiofCocgLRabZkDnY2NjXXXByLDIJfLMO7J+3uBvt8bLWE1RERE5VfhAPTUU09hwoQJuHnz/vVfbty4gYkTJ6Jnz57VWhzVfc+0coGHXdFNUQ/G3EH41bsSV0RERPR4FQ5A33//PdLT0+Hp6Qlvb294e3vDy8sL6enpWLBgQU3USHWYkUKOsB4l9gLt4V4gIiKq+yp8Fpi7uztOnjyJXbt24dKlSwAAPz8/hISEVHtxVD8MaOuGb3dH40ZqDvZGJuP0tVS0dreWuiwiIqKHqrYLITYkvBBixf165Cr+b+M5AEA3Hwf8b0RHiSsiIiJDU5Hv73IfAtuzZw/8/f2Rnp5ealpaWhpatGiB/fv3V7xaahBeau8ON2sTAMC/Uck4doVnhBERUd1V7gA0f/58jBw5ssxEZWVlhdGjR2PevHnVWhzVH0ojOSaENNO9/mpHJK8LREREdVa5A9Dp06fRp0+fh07v3bs3wsPDq6Uoqp+eb+uGJg5mAIBjcSnYH31b4oqIiIjKVu4AlJiY+MgbnRoZGSE5OblaiqL6yUghx8QQH93rr/7mXiAiIqqbyh2A3NzccO7cuYdOP3PmDFxcXKqlKKq/+rV0ga+zBQDgzPU0/H0hUeKKiIiISit3AHr66acxbdo05ObmlpqWk5ODGTNm4JlnnqnW4qj+kctleLd3c93reX9HQavlXiAiIqpbyh2A/u///g8pKSnw8fHBF198gU2bNmHTpk34/PPP0bx5c6SkpGDq1KmVKmLhwoXw9PSEWq1Gp06dcOzYsUf2T01NRVhYGFxcXKBSqeDj44Nt27bpps+ZMwcdOnSAhYUFHB0dMWDAAERGRlaqNqq4ED9H3XWAIhMzsDHihrQFERERPaDcAcjJyQmHDh1CQEAApkyZgoEDB2LgwIH46KOPEBAQgAMHDsDJyanCBaxZswaTJk3CjBkzcPLkSbRu3RqhoaFISkoqs39+fj569eqFuLg4rFu3DpGRkVi6dCnc3Nx0ffbt24ewsDAcOXIEO3fuREFBAXr37o2srKwK10cVJ5PJ8GHo/b1AX+2IRG6BRsKKiIiI9FXqQoh3795FTEwMhBBo1qwZbGxsKl1Ap06d0KFDB3z//fcAim626u7ujrfffhuTJ08u1X/x4sX48ssvcenSpUcOyi4pOTkZjo6O2LdvH7p16/bY/rwQYvUYvuwY9kYWDYz/oE9zvFXilhlERETVrUYuhFiSjY0NOnTogI4dO1Yp/OTn5yM8PFzvNhpyuRwhISE4fPhwmfNs3rwZQUFBCAsLg5OTEwICAjB79mxoNA/fw5CWlgYAsLW1LXN6Xl4e0tPT9R5UdVOe9oNcVvR80d7LuJOZJ21BRERE91QqAFWX27dvQ6PRlDp05uTkhISEhDLniY2Nxbp166DRaLBt2zZMmzYNX3/9NT777LMy+2u1WrzzzjsIDg5GQEBAmX3mzJkDKysr3cPd3b1qK0YAAB8nC7zUvuizzMgrxHe7eaNUIiKqGyQNQJWh1Wrh6OiIJUuWIDAwEIMGDcLUqVOxePHiMvuHhYXh3LlzWL169UOXOWXKFKSlpeke165dq6nyDc6kXj4wMVYAAFYejUdscqbEFREREUkcgOzt7aFQKJCYqH+tmMTERDg7O5c5j4uLC3x8fKBQKHRtfn5+SEhIQH5+vl7fcePGYcuWLdi7dy8aNWr00DpUKhUsLS31HlQ9HC3VGNWtCQCgUCvw+fZLEldEREQkcQBSKpUIDAzE7t27dW1arRa7d+9GUFBQmfMEBwcjJiYGWq1W1xYVFQUXFxcolUoAgBAC48aNw4YNG7Bnzx54eXnV7IrQI43q1gQOFioAwI7ziTgae0fiioiIyNBJfghs0qRJWLp0KVasWIGLFy9i7NixyMrKwvDhwwEAQ4YMwZQpU3T9x44di5SUFEyYMAFRUVHYunUrZs+ejbCwMF2fsLAw/Prrr1i1ahUsLCyQkJCAhIQE5OTk1Pr6EWCmMsKkXvdvkTFj83kUarSPmIOIiKhmGUldwKBBg5CcnIzp06cjISEBbdq0wfbt23UDo+Pj4yGX389p7u7u2LFjByZOnIhWrVrBzc0NEyZMwIcffqjrs2jRIgBAjx499N5r2bJlGDZsWI2vE5X2Unt3rDx6FedupONSQgZ+OxaP14M8pS6LiIgMVKWuA9TQ8TpANSP8agpeWFR0eQMrE2Psfa8HbM2UEldFREQNRY1fB4ioMgI9bPF826IrdqflFODrv3l7EiIikgYDENWqyX19YaYsOoNv1bF4nLuRJnFFRERkiBiAqFY5WqoxvmczAIAQwMebz4NHYYmIqLYxAFGtGx7shSYOZgCAE1fvYl34dYkrIiIiQ8MARLVOaSTHx/1b6F7P3nYRKVn5j5iDiIioejEAkSS6+Tigf2tXAMDd7ALM2npR4oqIiMiQMACRZKY94wdLddGlqNafvI5Dl29LXBERERkKBiCSjKOFGpP7+ule/9+Gc8gt0EhYERERGQoGIJLUyx3c0d7DBgAQezsLP/xzWeKKiIjIEDAAkaTkchlmP98SRnIZAGDRPzGITsyQuCoiImroGIBIcj5OFhjdvQkAoEAj8N66M7xZKhER1SgGIKoT3n6qGbzvXRvo9LVULN1/ReKKiIioIWMAojpBbazAly+2xr0jYfhmZxQPhRERUY1hAKI6o11jG4zsWnQoLF+j5aEwIiKqMQxAVKdM7OWju00GD4UREVFNYQCiOkVtrMCX/9E/FBaZwENhRERUvRiAqM4J9LDBmyUOhU1YfQp5hbxAIhERVR8GIKqTJvXyQXMnCwDApYQMfLk9UuKKiIioIWEAojpJbazAt6+0gdKo6Ef0vweuYH90ssRVERFRQ8EARHWWr7MlPuzjq3v97u+nkZKVL2FFRETUUDAAUZ02vLMnujazBwAkZeRhyh9nIISQuCoiIqrvGICoTpPLZfj6xdawMTUGAOw4n4jVx69JXBUREdV3DEBU5zlaqvH5C610rz/efB4Xb6VLWBEREdV3DEBUL/Ru4YzXnmgMAMgr1CJs5Ulk5hVKXBUREdVXDEBUb/xfP3+0cLUEAMTezsLk9RwPRERElcMARPWG2liBHwa3g4XKCACw5cwt/HrkqsRVERFRfcQARPWKh50Zvnzx/nigT7dcxJnrqdIVRERE9RIDENU7fQJcMCLYC0DRrTLeWnkSqdm8PhAREZUfAxDVS5P7+qJtY2sAwPW7OXj7t1Mo1GilLYqIiOoNBiCql5RGcnz/ajvYmikBAPujb+Pz7ZckroqIiOoLBiCqt9ysTfDD4HYwkssAAEv3X8GGU9clroqIiOoDBiCq155oYocZz7bQvf5w/VkOiiYiosdiAKJ677VOjfFKR3cAQH6hFqN/CUdSRq7EVRERUV3GAET1nkwmw8xnA9DewwYAcCstF6N/CUdugUbiyoiIqK5iAKIGQWkkx6LXAuFipQYAnIpPxaTfI6DV8krRRERUGgMQNRgOFiosHdIepkoFAGDb2QR8voNnhhERUWkMQNSgBLhZYeGr7XDvxDD8uC+Wt8sgIqJSGICowXnS1xEznwvQvZ6+6Rz2RiZJWBEREdU1DEDUIL3+hAdGdWsCANAKYNzKkzh7PU3iqoiIqK5gAKIGa3IfX/QNcAYAZOVrMHTZMVxOzpS4KiIiqgsYgKjBkstl+GZQG3TwLDo9PiUrH0N+OoZbaTkSV0ZERFJjAKIGTW2swH+HdoCvswUA4EZqDl7/6RjuZvHu8UREhowBiBo8KxNj/O+NjvCwMwUAxCRlYtjy48jKK5S4MiIikkqdCEALFy6Ep6cn1Go1OnXqhGPHjj2yf2pqKsLCwuDi4gKVSgUfHx9s27atSsukhs3RQo1fRnSCg4UKAHD6WipG/u8ErxZNRGSgJA9Aa9aswaRJkzBjxgycPHkSrVu3RmhoKJKSyj5tOT8/H7169UJcXBzWrVuHyMhILF26FG5ubpVeJhmGxnam+OWNjrBUGwEADl2+wxBERGSgZEIISe8V0KlTJ3To0AHff/89AECr1cLd3R1vv/02Jk+eXKr/4sWL8eWXX+LSpUswNjaulmU+KD09HVZWVkhLS4OlpWUV1o7qopPxdzHkp2PIvHcI7MnmDlj8eiBURgqJKyMioqqoyPe3pHuA8vPzER4ejpCQEF2bXC5HSEgIDh8+XOY8mzdvRlBQEMLCwuDk5ISAgADMnj0bGo2m0svMy8tDenq63oMarnaNbbB8eAfdLTP2RiYjbOVJ5BdqJa6MiIhqi6QB6Pbt29BoNHByctJrd3JyQkJCQpnzxMbGYt26ddBoNNi2bRumTZuGr7/+Gp999lmllzlnzhxYWVnpHu7u7tWwdlSXtfe0xbJhHWBiXBSCdl1Mwtu/nUSBhiGIiMgQSD4GqKK0Wi0cHR2xZMkSBAYGYtCgQZg6dSoWL15c6WVOmTIFaWlpuse1a9eqsWKqqzo1scNPQ9tDZVT0a7DjfCLG/hrOMUFERAZA0gBkb28PhUKBxMREvfbExEQ4OzuXOY+Liwt8fHygUNwfr+Hn54eEhATk5+dXapkqlQqWlpZ6DzIMnZva478lQtCui0l4Y8VxZOfzFHkiooZM0gCkVCoRGBiI3bt369q0Wi12796NoKCgMucJDg5GTEwMtNr7hyqioqLg4uICpVJZqWWSYevazAHLSowJOhhzB0N+Oob03AKJKyMiopoi+SGwSZMmYenSpVixYgUuXryIsWPHIisrC8OHDwcADBkyBFOmTNH1Hzt2LFJSUjBhwgRERUVh69atmD17NsLCwsq9TKIHdfa2xy9vdILFvVPkT1y9i1eXHkEKrxhNRNQgGUldwKBBg5CcnIzp06cjISEBbdq0wfbt23WDmOPj4yGX389p7u7u2LFjByZOnIhWrVrBzc0NEyZMwIcffljuZRKVJdDDBr+NfAJDfj6GlKx8nLuRjpeXHMb/RnSCs5Va6vKIiKgaSX4doLqI1wEybNGJGRj836NIysgDALhaqbFiREc0c7KQuDIiInqUenMdIKK6qJmTBdaOCYK7rQkA4GZaLl5YdAjH41IkroyIiKoLAxBRGTzszLB+bGcEuBX9BZGeW4jB/z2K7eduSVwZERFVBwYgoodwtFBj9aggdPNxAADkF2oxduVJrDgUJ21hRERUZQxARI9grjLCT0Pb4/l2RTfbFQKYsfk8PvnzAgp51WgionqLAYjoMYwVcnz9YmuEPemta/v54BW8seIErxVERFRPMQARlYNMJsP7ob6Y+3xLGMllAIB9Ucl4/odDuHonS+LqiIioohiAiCrg5Y6N8csbnWBtagwAiEnKxHMLD+Lw5TsSV0ZERBXBAERUQUHedtgUFoymjuYAgNTsArz+01EsP3gFvKwWEVH9wABEVAkedmb4463O6NG86AyxQq3Ax39ewITVEbyRKhFRPcAARFRJlmpj/DS0A0Z3a6Jr23z6JgYsPIjY5EwJKyMiosdhACKqAoVchilP+2Hxa+1griq6tV5UYiae/f4gtp9LkLg6IiJ6GAYgomrQJ8AFm8YFw8epaFxQZl4hxvwajllbLyC/kNcLIiKqaxiAiKqJt4M5NrwVjGdbu+ralu6/gv8sPoQrt3mqPBFRXcIARFSNzFRG+PblNvi4vz+MFUXXCzpzPQ39vtuP9eHXeZYYEVEdwQBEVM1kMhmGBXthw1vBaGJvBgDIztfg3bWn8c6aCGTw6tFERJJjACKqIQFuVvjz7S54qX0jXdumiJt4+rv9OB6XImFlRETEAERUg8xURvjiP62x4JW2sLh3lti1lBy89ONhfLblAnILNBJXSERkmBiAiGpB/9au2DahK9p72AAouqv8fw9cwdPf7cep+LsSV0dEZHgYgIhqibutKdaMDsJHT/tCaVT0qxebnIUXFh3C59svIa+Qe4OIiGoLAxBRLVLIZRjVzRtb3+6C1o2sAABaASz65zL6fXeAY4OIiGoJAxCRBJo5WWD92M54P7S57nT5mKRMvLj4MKb8cQZp2TxTjIioJjEAEUnESCFH2JNNsXnc/b1BAPDbsWvoOe8fbIq4wesGERHVEAYgIon5uVjij7eC8XF/f5gpFQCA25n5mLA6AkOXHUf8nWyJKyQiangYgIjqAIW86OKJu97tjt7+Trr2f6OSEfLNPnz9dySy8wslrJCIqGFhACKqQ1ysTLBkSHv8+HognC3VAID8Qi0W7IlBz6/3YfPpmzwsRkRUDRiAiOqg0BbO2DmpG0Z3a6IbJH0rLRfjfzuFQT8ewfmbaRJXSERUv8kE/5wsJT09HVZWVkhLS4OlpaXU5ZCBi03OxKdbLmBvZLKuTS4DBnVwxzshPnC6t6eIiMjQVeT7mwGoDAxAVBftvZSET7ZcwJXbWbo2tbEcb3ZpgtHdm8BCbSxhdURE0mMAqiIGIKqr8gu1WHbwCr7fE4OMvPuDom3NlBj3ZFMMfqIxVEYKCSskIpIOA1AVMQBRXZeSlY/v98TglyNxKNDc/xV2tzXBu72ao39rVyjkMgkrJCKqfQxAVcQARPVF/J1sfL0zEpsibuq1ezuYYXzPZnimFYMQERkOBqAqYgCi+ubcjTTM+esiDsbc0Wtv5miO8T2boV9LF8gZhIiogWMAqiIGIKqPhBA4HHsH83dG49gDN1X1cTLHhJ4+6BvgzCBERA0WA1AVMQBRfSaEwMGYO/hmVxTCr97Vm9bEwQxjunnjubauHCxNRA0OA1AVMQBRQyCEwIGY2/hmZxROxqfqTXOyVOGNLl54tZMHzFVG0hRIRFTNGICqiAGIGhIhBPZH38YP/8TgSKz+oTFLtRFeD/LAsM5ecLBQSVQhEVH1YACqIgYgaqhOxd/F4n2XseN8ol67UiFH/9auGB7siQA3K4mqIyKqGgagKmIAooYuJikTS/69jA2nbuhdRwgAOnjaYFhnL4S2cIKRgrcLJKL6gwGoihiAyFDcSsvB8kNxWH3sGtJyCvSmuVqp8VqQB17p0Bg2ZkqJKiQiKj8GoCpiACJDk51fiA2nbmD5wThEJ2XqTVMq5Ojb0hmvdGyMTl62kMl4Gj0R1U0MQFXEAESGqvgU+uWHrmD3pSQ8+L9DEwczvNKhMV4IbARb7hUiojqGAaiKGICIgLjbWfj1yFWsO3kdqdn6h8eUCjn6BDjj5Y7ueMLLjhdXJKI6gQGoihiAiO7LLdBgx/kE/HYsvtRp9ADQyMYEz7d1w8B2jeBlbyZBhURERSry/V0nTvFYuHAhPD09oVar0alTJxw7duyhfZcvXw6ZTKb3UKvVen0yMzMxbtw4NGrUCCYmJvD398fixYtrejWIGiS1sQLPtXHD6lFB2P1ud4zq1kTv8Nf1uzn4bk8MnvzqHwz84SB+OXIVqdn5ElZMRPR4kl8Cds2aNZg0aRIWL16MTp06Yf78+QgNDUVkZCQcHR3LnMfS0hKRkZG61w8Oypw0aRL27NmDX3/9FZ6envj777/x1ltvwdXVFc8++2yNrg9RQ+btYI6PnvbDu7198Pf5RKwLv4790cnQ3tuPfCo+FafiU/HpnxfwlK8jBrR1RY/mjlAb87YbRFS3SH4IrFOnTujQoQO+//57AIBWq4W7uzvefvttTJ48uVT/5cuX45133kFqaupDlxkQEIBBgwZh2rRpurbAwED07dsXn3322WNr4iEwovJLSs/FpoibWH/yOi4lZJSabqZUIMTfCc+0ckU3H3veg4yIaky9OQSWn5+P8PBwhISE6NrkcjlCQkJw+PDhh86XmZkJDw8PuLu747nnnsP58+f1pnfu3BmbN2/GjRs3IITA3r17ERUVhd69e5e5vLy8PKSnp+s9iKh8HC3VGNmtCba/0w3bxnfFm128YG9+/7YaWfkabIq4iZH/O4H2n+7CpDUR2HMpEfmFWgmrJiJDJ+khsNu3b0Oj0cDJyUmv3cnJCZcuXSpznubNm+Pnn39Gq1atkJaWhq+++gqdO3fG+fPn0ahRIwDAggULMGrUKDRq1AhGRkaQy+VYunQpunXrVuYy58yZg5kzZ1bvyhEZIH9XS/i7+mNyX18cvHwHW07fxI7zCUjPLQQAZOQV4o9TN/DHqRuwVBshxN8Jvf2d0M3HAaZKyY/IE5EBkfQQ2M2bN+Hm5oZDhw4hKChI1/7BBx9g3759OHr06GOXUVBQAD8/P7zyyiv49NNPAQBfffUVli5diq+++goeHh74999/MWXKFGzYsEFvb1OxvLw85OXl6V6np6fD3d2dh8CIqkF+oRYHYpKx5cwt7DyfiIy8wlJ9VEZydGlqj17+Tujp58QbsxJRpVTkEJikf3LZ29tDoVAgMVH/xoyJiYlwdnYu1zKMjY3Rtm1bxMTEAABycnLw0UcfYcOGDejXrx8AoFWrVoiIiMBXX31VZgBSqVRQqfgfLlFNUBrJ8ZSvE57ydUJeoQb/Rt3G1jM3sfNCIrLyNQCAvEItdl9Kwu5LSZDJzqKtuzV6+Tujl78TvB3MePVpIqp2kgYgpVKJwMBA7N69GwMGDABQNAh69+7dGDduXLmWodFocPbsWTz99NMAivYIFRQUQC7XH96kUCig1XLMAZGUVEYK9PJ3Qi//ojB06PId7LyQiF0XEpGUUbQXVgjgZHwqTsan4vPtl+Bua4IePo7o7uOAIG87mKl4qIyIqk7y/0kmTZqEoUOHon379ujYsSPmz5+PrKwsDB8+HAAwZMgQuLm5Yc6cOQCATz75BE888QSaNm2K1NRUfPnll7h69SrefPNNAEWnyHfv3h3vv/8+TExM4OHhgX379uF///sf5s2bJ9l6EpE+lZECTzZ3xJPNHfHZcwE4cyMNOy8kYOeFREQl3r8f2bWUHPxy5Cp+OXIVxgoZOnjaokdzB3T3cYSPkzn3DhFRpUgegAYNGoTk5GRMnz4dCQkJaNOmDbZv364bGB0fH6+3N+fu3bsYOXIkEhISYGNjg8DAQBw6dAj+/v66PqtXr8aUKVMwePBgpKSkwMPDA7NmzcKYMWNqff2I6PHkchnauFujjbs13g/1xdU7Wdh5IRF7LiXheFwKCjRFQxULNAKHLt/Boct3MHvbJThbqtHdxwHBzewR1MSOY4eIqNwkvw5QXcTrABHVHZl5hTh8+Q72RSXhn8hkXL+b89C+Pk7mCGpihyBvezzRxBbWprxhK5Eh4b3AqogBiKhuEkIg9nYW9kUmY19UMo7E3kHeQ64nJJMBLVwt0dnbHkHedujgaQtzjh8iatAYgKqIAYiofsgt0OB4XAoO3zssduZ6qu62HA+Sy4quU9TewxbtPW3QwdMWTpbqsjsTUb3EAFRFDEBE9VN6bgGOX7kfiC7cevRV3d1tTdDBwxbtPYtCUVMHc8jlHFRNVF8xAFURAxBRw5CSlY+jsUVh6HhcCiITM/Co//GsTIzRrrE1WrsXPdo0soaNGccREdUXDEBVxABE1DCl5RTgZPxdhMfdxfG4FERcS33oGKJiHnamaN3oXiByt0ILVyve3Z6ojmIAqiIGICLDkF+oxbmbaTgRl4LjcXcRfvUuUrLyHzmPQi6Dr7MFWrtbI8DVCi1cLdHc2YKhiKgOYACqIgYgIsMkhMC1lBxEXE9FRHwqTl9PxbkbaY/dS6SQy9DUwRwtXC3h72qJFq5W8He1hJWJcS1VTkQAA1CVMQARUbECjRaRCRk4fT0Vp6+lIuJaKqKTMh85lqhYIxsTtLgXiHydLdDc2QLuNqYcaE1UQxiAqogBiIgeJTOvEOdupOHCzXScv5mO8zfTEJOUicKHnYNfgomxAs2czNHcqSgQ+dz719FCxdt6EFURA1AVMQARUUXlFmgQnZiJ8zfTdKHo4q0M5BRoyjW/lYkxmjtZwMe5KBx5O5rD28GcwYioAhiAqogBiIiqg0YrcOV2Fi7cSkd0YgYiEzIQlZiBqynZ5TqEBgDmKiM0cTBDE3szeDuYo4mDObwdzeBpZ8aB10QPqMj3N68LT0RUQxRyGZo6mqOpo7lee06+BtFJ9wNRZGImohIykJCeW2oZmXmFOHM9DWeup+m1y2SAm7XJvVBkhiYO5vCyM4OHnSlcrNQwUshLLYuI7uMeoDJwDxARSSEtuwBR94JRbHIWYm9n4nJyJq7fzSn3HiMAMJLL0MjGBB73AlFjW1N42JnB084U7ram3HNEDRYPgVURAxAR1SW5BRrE3ckqCkXJmbhc4t/MvMIKL8/ZUo3GdqbwsDWFh50p3GxM4GZd9K+zpRoKnqVG9RQDUBUxABFRfSCEQHJGHmKSMxGbnIX4lGxcvZOFq3eyEZ+Sjez88g3ALslILoOzlRpu1iZwszFBI2sTNLIpDkkmcLFWQ2XEPUhUNzEAVREDEBHVd0II3M7M1wWiqynZiL+Tde/fbNx5zBWvH0YmAxzMVWhkYwJXaxO4WKnhZKmGi5UJnK3UcLZSw9FCBWOOQSIJMABVEQMQETV0GbkFuHonG9fvZuP63RzcSM3Bjbs5uudpOQWVXrZMBtibq0qEo6Jg5Gyp/6+pkufhUPXiWWBERPRIFmpjBLhZIcDNqszpmXmF9wJRtl44un7v+e3MvIcuWwggOSMPyRl5ANIe2s9SbQQHCxUcLdRwsFDpHo4lnjuYq2BjquTVs6naMQAREVEp5iojNL93+46y5BZocCstFwlpuUhIz0FCWh4S0nKQkF7UdistF8mZeY88ey09txDpuYW4nJz1yFqM5DLYm+uHIkfL+8/tzFWwNVPCzkwJKxNjhiUqFwYgIiKqMLWxAl72ZvCyN3tonwKNFskZebpQVBSW9J8nZ+Q99mrZhVpRNF8Z10l6kEIug42pMezMikKRrXlRMCoOSLb32u3utVubKnnWm4FiACIiohphrJDD1bposPSjZOUVIuneIbOiR9Heo6T0PCRn3m+/nZmHx91uTaMtGvx9O7N8g7xlMsDGtCgg2ZopYWuqhLWpMayL/zUp8dzUGDamRXuZeC2l+o8BiIiIJGWmMoKXyuiRe5OAonBzNztfLxglZeQiJTMfKVn5uJN179/MPNzJykdeofax7y0EkHJvvoowMVbA2tQYViZFoejB0GRjqoRViQBloTaCpYkxzJQK3tutjmAAIiKiekFxbyyQvbnqsX2FEMjO15QIRnm4k1kyJBW1lQxOFbluUk6BBjlpReOgKkIuAyxNjGGpNi4KRWpjWJoY3Xt9/3lRH6NSbRYqI45xqiYMQERE1ODIZDKYqYxgpjKCu61puebJydcgNScfqdkFuJudj7TsAqTm3H9+N7toWmpOAVKLn2cXIF/z+D1NxbQCuvkqt16AubJob1JxgDJTKWCuNoa5SgHze+tsXvxQF722KKPd0K/VxABEREQEwESpgInSBC5Wjx6zVJIQAjkFGl2oSc3O14Wm4tfpOYVIzy1ARm7Rv+k5BUVnwOUUoPBxg5pKvR+QkVeIjErcAuVBKiP5/ZCkLPq3OCCZqYxgUaLdTKmAqcoIpsYKmKoUMFMawfRem5lSAVOlEZRG9StQMQARERFVkkwmg6nSCKZKo8cO9n6QEAK5BdoSoahAF5aKA1JxW0YZbem5Bcgvxzinh8kr1CKvML/SVwV/kJFcBlOlAmYqI5go74ek+68V9z6rojZTpQKDO3lIFpwYgIiIiCQgk8nu7XVSwMlSXall5BVqkJWnQVZeITJyC5GVX4jM3EJk5hU9dO1599v02kv0L9BU7cYQhVqhu7ZTeb32hEeV3rMqGICIiIjqKZWRAiojBWzNlFVeVl6hBpm5hcjK0yAjrwBZeRpk5hUgM0+D7LxCZOdrkJ1fiKz8kq81yMovRHZe0b85D7x+1BE+pZFc0nFIDEBERERUFKbMFbAzr57lCSGQV6gtCkklAlTx66rucaoqBiAiIiKqdjKZDGpjBdTG1bOHqrrVryHbRERERNWAAYiIiIgMDgMQERERGRwGICIiIjI4DEBERERkcBiAiIiIyOAwABEREZHBYQAiIiIig8MARERERAaHAYiIiIgMDgMQERERGRwGICIiIjI4DEBERERkcHg3+DIIIQAA6enpEldCRERE5VX8vV38Pf4oDEBlyMjIAAC4u7tLXAkRERFVVEZGBqysrB7ZRybKE5MMjFarxc2bN2FhYQGZTFaty05PT4e7uzuuXbsGS0vLal02VRy3R93C7VH3cJvULdwejyaEQEZGBlxdXSGXP3qUD/cAlUEul6NRo0Y1+h6Wlpb84a1DuD3qFm6PuofbpG7h9ni4x+35KcZB0ERERGRwGICIiIjI4DAA1TKVSoUZM2ZApVJJXQqB26Ou4faoe7hN6hZuj+rDQdBERERkcLgHiIiIiAwOAxAREREZHAYgIiIiMjgMQERERGRwGIBq0cKFC+Hp6Qm1Wo1OnTrh2LFjUpfUIM2ZMwcdOnSAhYUFHB0dMWDAAERGRur1yc3NRVhYGOzs7GBubo4XXngBiYmJen3i4+PRr18/mJqawtHREe+//z4KCwtrc1UapLlz50Imk+Gdd97RtXF71K4bN27gtddeg52dHUxMTNCyZUucOHFCN10IgenTp8PFxQUmJiYICQlBdHS03jJSUlIwePBgWFpawtraGm+88QYyMzNre1UaBI1Gg2nTpsHLywsmJibw9vbGp59+qnc/K26TGiCoVqxevVoolUrx888/i/Pnz4uRI0cKa2trkZiYKHVpDU5oaKhYtmyZOHfunIiIiBBPP/20aNy4scjMzNT1GTNmjHB3dxe7d+8WJ06cEE888YTo3LmzbnphYaEICAgQISEh4tSpU2Lbtm3C3t5eTJkyRYpVajCOHTsmPD09RatWrcSECRN07dwetSclJUV4eHiIYcOGiaNHj4rY2FixY8cOERMTo+szd+5cYWVlJTZu3ChOnz4tnn32WeHl5SVycnJ0ffr06SNat24tjhw5Ivbv3y+aNm0qXnnlFSlWqd6bNWuWsLOzE1u2bBFXrlwRa9euFebm5uLbb7/V9eE2qX4MQLWkY8eOIiwsTPdao9EIV1dXMWfOHAmrMgxJSUkCgNi3b58QQojU1FRhbGws1q5dq+tz8eJFAUAcPnxYCCHEtm3bhFwuFwkJCbo+ixYtEpaWliIvL692V6CByMjIEM2aNRM7d+4U3bt31wUgbo/a9eGHH4ouXbo8dLpWqxXOzs7iyy+/1LWlpqYKlUolfvvtNyGEEBcuXBAAxPHjx3V9/vrrLyGTycSNGzdqrvgGql+/fmLEiBF6bc8//7wYPHiwEILbpKbwEFgtyM/PR3h4OEJCQnRtcrkcISEhOHz4sISVGYa0tDQAgK2tLQAgPDwcBQUFetvD19cXjRs31m2Pw4cPo2XLlnByctL1CQ0NRXp6Os6fP1+L1TccYWFh6Nevn97nDnB71LbNmzejffv2ePHFF+Ho6Ii2bdti6dKluulXrlxBQkKC3vawsrJCp06d9LaHtbU12rdvr+sTEhICuVyOo0eP1t7KNBCdO3fG7t27ERUVBQA4ffo0Dhw4gL59+wLgNqkpvBlqLbh9+zY0Go3ef94A4OTkhEuXLklUlWHQarV45513EBwcjICAAABAQkIClEolrK2t9fo6OTkhISFB16es7VU8jSpm9erVOHnyJI4fP15qGrdH7YqNjcWiRYswadIkfPTRRzh+/DjGjx8PpVKJoUOH6j7Psj7vktvD0dFRb7qRkRFsbW25PSph8uTJSE9Ph6+vLxQKBTQaDWbNmoXBgwcDALdJDWEAogYtLCwM586dw4EDB6QuxWBdu3YNEyZMwM6dO6FWq6Uux+BptVq0b98es2fPBgC0bdsW586dw+LFizF06FCJqzNMv//+O1auXIlVq1ahRYsWiIiIwDvvvANXV1dukxrEQ2C1wN7eHgqFotRZLYmJiXB2dpaoqoZv3Lhx2LJlC/bu3YtGjRrp2p2dnZGfn4/U1FS9/iW3h7Ozc5nbq3galV94eDiSkpLQrl07GBkZwcjICPv27cN3330HIyMjODk5cXvUIhcXF/j7++u1+fn5IT4+HsD9z/NR/185OzsjKSlJb3phYSFSUlK4PSrh/fffx+TJk/Hyyy+jZcuWeP311zFx4kTMmTMHALdJTWEAqgVKpRKBgYHYvXu3rk2r1WL37t0ICgqSsLKGSQiBcePGYcOGDdizZw+8vLz0pgcGBsLY2Fhve0RGRiI+Pl63PYKCgnD27Fm9/1B27twJS0vLUl8e9Gg9e/bE2bNnERERoXu0b98egwcP1j3n9qg9wcHBpS4LERUVBQ8PDwCAl5cXnJ2d9bZHeno6jh49qrc9UlNTER4eruuzZ88eaLVadOrUqRbWomHJzs6GXK7/daxQKKDVagFwm9QYqUdhG4rVq1cLlUolli9fLi5cuCBGjRolrK2t9c5qoeoxduxYYWVlJf755x9x69Yt3SM7O1vXZ8yYMaJx48Ziz5494sSJEyIoKEgEBQXpphefdt27d28REREhtm/fLhwcHHjadTUpeRaYENwetenYsWPCyMhIzJo1S0RHR4uVK1cKU1NT8euvv+r6zJ07V1hbW4tNmzaJM2fOiOeee67MU67btm0rjh49Kg4cOCCaNWvGU64raejQocLNzU13Gvwff/wh7O3txQcffKDrw21S/RiAatGCBQtE48aNhVKpFB07dhRHjhyRuqQGCUCZj2XLlun65OTkiLfeekvY2NgIU1NTMXDgQHHr1i295cTFxYm+ffsKExMTYW9vL959911RUFBQy2vTMD0YgLg9ateff/4pAgIChEqlEr6+vmLJkiV607VarZg2bZpwcnISKpVK9OzZU0RGRur1uXPnjnjllVeEubm5sLS0FMOHDxcZGRm1uRoNRnp6upgwYYJo3LixUKvVokmTJmLq1Kl6l3jgNql+MiFKXGqSiIiIyABwDBAREREZHAYgIiIiMjgMQERERGRwGICIiIjI4DAAERERkcFhACIiIiKDwwBEREREBocBiIjqrX/++QcymazUfcQq4uOPP0abNm2qrabqNmzYMAwYMEDqMogaHAYgonps2LBhkMlkmDt3rl77xo0bIZPJJKqqfnnvvff07rFU1wLHt99+i+XLl0tdBlGDwwBEVM+p1Wp8/vnnuHv3rtSllEt+fr7UJegxNzeHnZ1dtS+3utbTysoK1tbW1bIsIrqPAYiongsJCYGzszPmzJnz0D5lHeaZP38+PD09da+L93zMnj0bTk5OsLa2xieffILCwkK8//77sLW1RaNGjbBs2TK95Vy7dg0vvfQSrK2tYWtri+eeew5xcXGlljtr1iy4urqiefPmAICzZ8/iqaeegomJCezs7DBq1ChkZmY+cl23bdsGHx8fmJiY4Mknn9R7n2IHDhxA165dYWJiAnd3d4wfPx5ZWVnl+mw+/vhjrFixAps2bYJMJoNMJsM///xTpfX85Zdf0L59e1hYWMDZ2Rmvvvqq3l3tAeD8+fN45plnYGlpCQsLC3Tt2hWXL1/WW26xvLw8jB8/Ho6OjlCr1ejSpQuOHz+um158WHD37t1o3749TE1N0blz51J3gN+0aRPatWsHtVqNJk2aYObMmSgsLAQACCHw8ccfo3HjxlCpVHB1dcX48eMfuW2I6hsGIKJ6TqFQYPbs2ViwYAGuX79epWXt2bMHN2/exL///ot58+ZhxowZeOaZZ2BjY4OjR49izJgxGD16tO59CgoKEBoaCgsLC+zfvx8HDx6Eubk5+vTpo7cHZPfu3YiMjMTOnTuxZcsWZGVlITQ0FDY2Njh+/DjWrl2LXbt2Ydy4cQ+t7dq1a3j++efRv39/RERE4M0338TkyZP1+ly+fBl9+vTBCy+8gDNnzmDNmjU4cODAI5db0nvvvYeXXnoJffr0wa1bt3Dr1i107ty50utZ/Bl9+umnOH36NDZu3Ii4uDgMGzZMN8+NGzfQrVs3qFQq7NmzB+Hh4RgxYoQujDzogw8+wPr167FixQqcPHkSTZs2RWhoKFJSUvT6TZ06FV9//TVOnDgBIyMjjBgxQjdt//79GDJkCCZMmIALFy7gxx9/xPLlyzFr1iwAwPr16/HNN9/gxx9/RHR0NDZu3IiWLVuW6zMkqjckvhkrEVXB0KFDxXPPPSeEEOKJJ54QI0aMEEIIsWHDBlHy13vGjBmidevWevN+8803wsPDQ29ZHh4eQqPR6NqaN28uunbtqntdWFgozMzMxG+//SaEEOKXX34RzZs3F1qtVtcnLy9PmJiYiB07duiW6+TkpHdn6yVLlggbGxuRmZmpa9u6dauQy+UiISGhzHWdMmWK8Pf312v78MMPBQBx9+5dIYQQb7zxhhg1apRen/379wu5XC5ycnLKXO6Dn03Jz7RYZdezLMePHxcAdHfpnjJlivDy8hL5+fll9i9ZT2ZmpjA2NhYrV67UTc/Pzxeurq7iiy++EEIIsXfvXgFA7Nq1S9dn69atAoDuM+jZs6eYPXt2qXV0cXERQgjx9ddfCx8fn4fWRNQQcA8QUQPx+eefY8WKFbh48WKll9GiRQvI5ff/W3ByctL7y1+hUMDOzk53COf06dOIiYmBhYUFzM3NYW5uDltbW+Tm5uoO4QBAy5YtoVQqda8vXryI1q1bw8zMTNcWHBwMrVZb6lBNyXk6deqk1xYUFKT3+vTp01i+fLmuFnNzc4SGhkKr1eLKlSuV+ETuL7cy6wkA4eHh6N+/Pxo3bgwLCwt0794dABAfHw8AiIiIQNeuXWFsbPzYOi5fvoyCggIEBwfr2oyNjdGxY8dS271Vq1a65y4uLgCgt90++eQTvc9p5MiRuHXrFrKzs/Hiiy8iJycHTZo0wciRI7Fhw4aH7pEiqq+MpC6AiKpHt27dEBoaiilTpugdYgEAuVwOIYReW0FBQallPPglLJPJymzTarUAgMzMTAQGBmLlypWlluXg4KB7XjLo1KTMzEyMHj26zPEqjRs3rtJyK7OexYf6QkNDsXLlSjg4OCA+Ph6hoaG6Q2cmJiaVrutRSm634jMCS263mTNn4vnnny81n1qthru7OyIjI7Fr1y7s3LkTb731Fr788kvs27evXEGNqD5gACJqQObOnYs2bdroBuAWc3BwQEJCAoQQui/DiIiIKr9fu3btsGbNGjg6OsLS0rLc8/n5+WH58uXIysrShYaDBw9CLpeXqr3kPJs3b9ZrO3LkSKl6Lly4gKZNm1ZwTe5TKpXQaDSllluZ9bx06RLu3LmDuXPnwt3dHQBw4sQJvT6tWrXCihUrUFBQ8Nhw4e3tDaVSiYMHD8LDwwNAUZA9fvw43nnnnXLX1a5dO0RGRj7yczIxMUH//v3Rv39/hIWFwdfXF2fPnkW7du3K/T5EdRkPgRE1IC1btsTgwYPx3Xff6bX36NEDycnJ+OKLL3D58mUsXLgQf/31V5Xfb/DgwbC3t8dzzz2H/fv348qVK/jnn38wfvz4Rw7IHjx4MNRqNYYOHYpz585h7969ePvtt/H666/DycmpzHnGjBmD6OhovP/++4iMjMSqVatKXR/nww8/xKFDhzBu3DhEREQgOjoamzZtKvcgaADw9PTEmTNnEBkZidu3b6OgoKDS69m4cWMolUosWLAAsbGx2Lx5Mz799FO9PuPGjUN6ejpefvllnDhxAtHR0fjll1/KPBRoZmaGsWPH4v3338f27dtx4cIFjBw5EtnZ2XjjjTfKvY7Tp0/H//73P8ycORPnz5/HxYsXsXr1avzf//0fAGD58uX46aefcO7cOcTGxuLXX3+FiYmJLnQRNQQMQEQNzCeffKI71FHMz88PP/zwAxYuXIjWrVvj2LFjeO+996r8Xqampvj333/RuHFjPP/88/Dz88Mbb7yB3NzcR+4pMTU1xY4dO5CSkoIOHTrgP//5D3r27Invv//+ofM0btwY69evx8aNG9G6dWssXrwYs2fP1uvTqlUr7Nu3D1FRUejatSvatm2L6dOnw9XVtdzrNHLkSDRv3hzt27eHg4MDDh48WOn1dHBwwPLly7F27Vr4+/tj7ty5+Oqrr/T62NnZYc+ePcjMzET37t0RGBiIpUuXPnRv0Ny5c/HCCy/g9ddfR7t27RATE4MdO3bAxsam3OsYGhqKLVu24O+//0aHDh3wxBNP4JtvvtEFHGtrayxduhTBwcFo1aoVdu3ahT///LNGrpdEJBWZeHBgABEREVEDxz1AREREZHAYgIiIiMjgMAARERGRwWEAIiIiIoPDAEREREQGhwGIiIiIDA4DEBERERkcBiAiIiIyOAxAREREZHAYgIiIiMjgMAARERGRwWEAIiIiIoPz/8iq1o3JsRQVAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pyplot.plot(np.arange(len(J_historico)), J_historico, lw=2)\n",
    "pyplot.title(\"Grafica de la convergencia del costo\")\n",
    "pyplot.xlabel('Numero de iteraciones')\n",
    "pyplot.ylabel('Costo J')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Haciendo la prueba con un ejemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Una persona con las caracteristicas: [1, 58, 1, 159, 53, 110, 70, 1, 1, 0, 0, 1] \n",
      "Tiene una probabilidad de tener diabetes de: 24.532474098172727 %\n",
      "Con valores de theta: [-0.00425769  0.30448276 -0.01249678 -0.03148556  0.16772203  0.57638774\n",
      "  0.31814782  0.26580355  0.01098746 -0.0370134  -0.03405512 -0.07353863]\n"
     ]
    }
   ],
   "source": [
    "X_array = [1,58,1,159,53,110,70,1,1,0,0,1]\n",
    "X_array_copy = X_array.copy()\n",
    "#Se normaliza las caracteristicas para la prueba. haciendo el uso de mu y sigma calculados anteriormente, solamente los valores despues del primero, porque este es el 1.\n",
    "X_array[1:] = (X_array[1:] - mu) / sigma\n",
    "\n",
    "resultados = sigmoid(np.dot(X_array, theta)) \n",
    "\n",
    "print(f\"Una persona con las caracteristicas: {X_array_copy} \")\n",
    "print(f'Tiene una probabilidad de tener diabetes de: {resultados * 100} %')\n",
    "\n",
    "print(f\"Con valores de theta: { theta }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6 Ejemplos de Predicciones\n",
    "Se creo una matriz con 11 ejemplos, donde se hace las predicciones correspondientes:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.6.1 Definiendo nuestro umbral clasificador\n",
    "Donde:\n",
    "\n",
    "* Si $h(\\theta)$ >= 0.5, predice \"y = 1\".\n",
    "* Si $h(\\theta)$ < 0.5 , predice \"y = 0\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+----------+----------+-----------+----------+---------------+-----------+---------+-----------+---------------------+------------------+-------------------------+\n",
      "|   AGE |   GENDER |   HEIGHT |   WEIGHT |   AP_HIGH |   AP_LOW |   CHOLESTEROL |   GLUCOSE |   SMOKE |   ALCOHOL |   PHYSICAL_ACTIVITY |   CARDIO_DISEASE |   CARDIO_DISEASE(Si/No) |\n",
      "+=======+==========+==========+==========+===========+==========+===============+===========+=========+===========+=====================+==================+=========================+\n",
      "|    50 |        2 |      168 |       62 |       110 |       80 |             1 |         1 |       0 |         0 |                   1 |         0.248073 |                       0 |\n",
      "+-------+----------+----------+----------+-----------+----------+---------------+-----------+---------+-----------+---------------------+------------------+-------------------------+\n",
      "|    62 |        1 |      165 |       68 |       150 |       80 |             2 |         1 |       0 |         0 |                   0 |         0.816617 |                       1 |\n",
      "+-------+----------+----------+----------+-----------+----------+---------------+-----------+---------+-----------+---------------------+------------------+-------------------------+\n",
      "|    58 |        1 |      153 |       78 |       140 |       90 |             2 |         1 |       0 |         0 |                   1 |         0.782146 |                       1 |\n",
      "+-------+----------+----------+----------+-----------+----------+---------------+-----------+---------+-----------+---------------------+------------------+-------------------------+\n",
      "|    46 |        1 |      169 |       64 |       120 |       80 |             3 |         1 |       0 |         0 |                   1 |         0.470677 |                       0 |\n",
      "+-------+----------+----------+----------+-----------+----------+---------------+-----------+---------+-----------+---------------------+------------------+-------------------------+\n",
      "|    46 |        1 |      158 |       58 |       110 |       80 |             1 |         1 |       0 |         0 |                   1 |         0.219054 |                       0 |\n",
      "+-------+----------+----------+----------+-----------+----------+---------------+-----------+---------+-----------+---------------------+------------------+-------------------------+\n",
      "|    60 |        2 |      170 |       69 |       120 |       80 |             1 |         1 |       1 |         1 |                   1 |         0.372527 |                       0 |\n",
      "+-------+----------+----------+----------+-----------+----------+---------------+-----------+---------+-----------+---------------------+------------------+-------------------------+\n",
      "|    52 |        2 |      171 |       98 |       110 |       90 |             1 |         1 |       0 |         0 |                   1 |         0.430965 |                       0 |\n",
      "+-------+----------+----------+----------+-----------+----------+---------------+-----------+---------+-----------+---------------------+------------------+-------------------------+\n",
      "|    52 |        1 |      153 |       63 |       110 |       70 |             2 |         1 |       0 |         0 |                   1 |         0.296694 |                       0 |\n",
      "+-------+----------+----------+----------+-----------+----------+---------------+-----------+---------+-----------+---------------------+------------------+-------------------------+\n",
      "|    59 |        2 |      165 |       65 |       120 |       80 |             1 |         1 |       0 |         0 |                   1 |         0.422599 |                       0 |\n",
      "+-------+----------+----------+----------+-----------+----------+---------------+-----------+---------+-----------+---------------------+------------------+-------------------------+\n",
      "|    64 |        1 |      148 |       50 |       120 |       80 |             2 |         1 |       0 |         0 |                   1 |         0.554715 |                       1 |\n",
      "+-------+----------+----------+----------+-----------+----------+---------------+-----------+---------+-----------+---------------------+------------------+-------------------------+\n",
      "|    54 |        2 |      169 |       55 |       120 |       80 |             1 |         1 |       1 |         0 |                   1 |         0.30985  |                       0 |\n",
      "+-------+----------+----------+----------+-----------+----------+---------------+-----------+---------+-----------+---------------------+------------------+-------------------------+\n"
     ]
    }
   ],
   "source": [
    "nombres_columnas = ['AGE','GENDER','HEIGHT','WEIGHT','AP_HIGH','AP_LOW','CHOLESTEROL','GLUCOSE','SMOKE','ALCOHOL','PHYSICAL_ACTIVITY','CARDIO_DISEASE', 'CARDIO_DISEASE(Si/No)']\n",
    "\n",
    "matriz_datos = np.array([\n",
    "[50,2,168,62,110,80,1,1,0,0,1],\n",
    "[62,1,165,68,150,80,2,1,0,0,0],\n",
    "[58,1,153,78,140,90,2,1,0,0,1],\n",
    "[46,1,169,64,120,80,3,1,0,0,1],\n",
    "[46,1,158,58,110,80,1,1,0,0,1],\n",
    "[60,2,170,69,120,80,1,1,1,1,1],\n",
    "[52,2,171,98,110,90,1,1,0,0,1],\n",
    "[52,1,153,63,110,70,2,1,0,0,1],\n",
    "[59,2,165,65,120,80,1,1,0,0,1],\n",
    "[64,1,148,50,120,80,2,1,0,0,1],\n",
    "[54,2,169,55,120,80,1,1,1,0,1],\n",
    "])\n",
    "\n",
    "para_tabla = matriz_datos.copy()\n",
    "#creamos un vector parta almacenar cada Y predicha\n",
    "y_pre = []\n",
    "\n",
    "matriz_datos = (matriz_datos- mu) / sigma\n",
    "matriz_datos = np.concatenate([np.ones((len(matriz_datos), 1)), matriz_datos], axis=1)\n",
    "\n",
    "# Calculamos la Y predicha de los 11 ejemplos de prediccion\n",
    "# Calculamos la Y predicha de cada fila de la matriz\n",
    "for j in matriz_datos:\n",
    "    y_pre.append(sigmoid(np.dot(j, theta)))\n",
    "\n",
    "# Convertimos la lista a un array unidimensional\n",
    "\n",
    "y_pre = np.array(y_pre)\n",
    "\n",
    "# usamos umbral para definir si tiene o no la enfermedad\n",
    "y_pre_umbral = (y_pre >= 0.5).astype(int)\n",
    "\n",
    "para_tabla = np.column_stack((para_tabla, y_pre))\n",
    "para_tabla = np.column_stack((para_tabla, y_pre_umbral))\n",
    "# Convertir la matriz en una lista de listas\n",
    "datos_para_tabla = para_tabla.tolist()\n",
    "\n",
    "# Imprimir la tabla\n",
    "print(tabulate(datos_para_tabla, headers=nombres_columnas, tablefmt='grid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.7 Validaciones\n",
    "Para hacer las validaciones correspondientes se hizo el uso siguiendo el consejo de 80/20, donde 80% es para la fase de entrenamiento, y 20% es para la fase de prueba."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.7.1 Normalizamos el X_test que es el 20% separado a un incio:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_norm_test = (X_test- mu) / sigma\n",
    "m_test= len(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.7.2 Concadenamos unos a matriz X normalizado del test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  X[:,0] X[:, 1]   X[:, 2]   X[:, 3] X[:, 4] X[:, 5] X[:, 6] X[:, 7]X[:, 8]   X[:, 9]  X[:, 10]  X[:, 11]\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "   1.000  -0.643    -0.730    -1.024  -0.844  -1.589  -1.183   0.931  -0.396    -0.310  -0.238   0.497\n",
      "   1.000   0.393    -0.730    -0.044   0.274  -0.393  -0.143  -0.538  -0.396    -0.310  -0.238   0.497\n",
      "   1.000   0.541    -0.730    -0.044   0.274  -0.393  -0.143  -0.538  -0.396    -0.310  -0.238   0.497\n",
      "   1.000   0.097    -0.730     0.323   2.160   1.999   1.935  -0.538  -0.396    -0.310  -0.238   0.497\n",
      "   1.000  -0.199    -0.730    -2.982   0.204   0.803   0.896  -0.538  -0.396    -0.310  -0.238   0.497\n",
      "   1.000  -0.495    -0.730     0.445  -0.076   1.401   0.896  -0.538  -0.396    -0.310  -0.238  -2.014\n",
      "   1.000   1.281     1.370    -0.534   0.902  -0.991  -1.183  -0.538  -0.396    -0.310  -0.238   0.497\n",
      "   1.000  -0.643    -0.730    -1.146   1.671  -0.393  -0.143  -0.538  -0.396    -0.310  -0.238   0.497\n",
      "   1.000  -0.199     1.370     0.078  -0.285   0.205  -0.143  -0.538  -0.396     3.226  -0.238   0.497\n",
      "   1.000   0.393     1.370     0.568  -0.425   0.803   0.896   0.931  -0.396    -0.310  -0.238   0.497\n"
     ]
    }
   ],
   "source": [
    "X_test_ready = np.concatenate([np.ones((m_test, 1)), X_norm_test], axis=1)\n",
    "\n",
    "# imprimir todos las X_norm de datos solo 10\n",
    "print('{:>8s}{:>8s}{:>10s}{:>10s}{:>8s}{:>8s}{:>8s}{:>8s}{:>6s}{:>10s}{:>10s}{:>10s}'.format(\n",
    "    'X[:,0]', 'X[:, 1]', 'X[:, 2]', 'X[:, 3]', 'X[:, 4]', 'X[:, 5]', 'X[:, 6]', 'X[:, 7]', 'X[:, 8]', 'X[:, 9]', 'X[:, 10]', 'X[:, 11]'\n",
    "))\n",
    "print('-' * 110)\n",
    "\n",
    "for i in range(10):\n",
    "    print('{:8.3f}{:8.3f}{:10.3f}{:10.3f}{:8.3f}{:8.3f}{:8.3f}{:8.3f}{:8.3f}{:10.3f}{:8.3f}{:8.3f}'.format(\n",
    "    X_test_ready[i, 0], X_test_ready[i, 1], X_test_ready[i, 2], X_test_ready[i, 3], X_test_ready[i, 4], X_test_ready[i, 5], X_test_ready[i, 6],\n",
    "    X_test_ready[i, 7], X_test_ready[i, 8], X_test_ready[i, 9], X_test_ready[i, 10], X_test_ready[i, 11]\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.7.3 Hacemos el calculo de Y predicha "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  X[:,0] X[:, 1]   X[:, 2]   X[:, 3] X[:, 4] X[:, 5] X[:, 6] X[:, 7]X[:, 8]   X[:, 9]  X[:, 10]  X[:, 11]         y     (y) usando el umbral\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------\n",
      "   1.000  -0.643    -0.730    -1.024  -0.844  -1.589  -1.183   0.931  -0.396    -0.310  -0.238   0.497           0.20              0\n",
      "   1.000   0.393    -0.730    -0.044   0.274  -0.393  -0.143  -0.538  -0.396    -0.310  -0.238   0.497           0.43              0\n",
      "   1.000   0.541    -0.730    -0.044   0.274  -0.393  -0.143  -0.538  -0.396    -0.310  -0.238   0.497           0.45              0\n",
      "   1.000   0.097    -0.730     0.323   2.160   1.999   1.935  -0.538  -0.396    -0.310  -0.238   0.497           0.88              1\n",
      "   1.000  -0.199    -0.730    -2.982   0.204   0.803   0.896  -0.538  -0.396    -0.310  -0.238   0.497           0.66              1\n",
      "   1.000  -0.495    -0.730     0.445  -0.076   1.401   0.896  -0.538  -0.396    -0.310  -0.238  -2.014           0.72              1\n",
      "   1.000   1.281     1.370    -0.534   0.902  -0.991  -1.183  -0.538  -0.396    -0.310  -0.238   0.497           0.36              0\n",
      "   1.000  -0.643    -0.730    -1.146   1.671  -0.393  -0.143  -0.538  -0.396    -0.310  -0.238   0.497           0.42              0\n",
      "   1.000  -0.199     1.370     0.078  -0.285   0.205  -0.143  -0.538  -0.396     3.226  -0.238   0.497           0.41              0\n",
      "   1.000   0.393     1.370     0.568  -0.425   0.803   0.896   0.931  -0.396    -0.310  -0.238   0.497           0.73              1\n"
     ]
    }
   ],
   "source": [
    "y_predicha =[]\n",
    "# Calculamos la Y predicha de cada fila de la matriz\n",
    "for dato in X_test_ready:\n",
    "    y_predicha.append(sigmoid(np.dot(dato, theta.T)))\n",
    "\n",
    "# Convertimos la lista a un array unidimensional\n",
    "y_predicha = np.array(y_predicha)\n",
    "\n",
    "#usando el umbral donde todo aquello que sea >= 0.5 sera 1, y si es menor sera 0\n",
    "y_umbral = (y_predicha >= 0.5).astype(int)\n",
    "\n",
    "# imprimir todos las X_norm de datos solo 10\n",
    "print('{:>8s}{:>8s}{:>10s}{:>10s}{:>8s}{:>8s}{:>8s}{:>8s}{:>6s}{:>10s}{:>10s}{:>10s}{:>10s}{:>25s}'.format(\n",
    "    'X[:,0]', 'X[:, 1]', 'X[:, 2]', 'X[:, 3]', 'X[:, 4]', 'X[:, 5]', 'X[:, 6]', 'X[:, 7]', 'X[:, 8]', 'X[:, 9]', 'X[:, 10]', 'X[:, 11]','y','(y) usando el umbral'\n",
    "))\n",
    "print('-' * 140)\n",
    "\n",
    "#Mostrando algunos datos\n",
    "for i in range(10):\n",
    "    print('{:8.3f}{:8.3f}{:10.3f}{:10.3f}{:8.3f}{:8.3f}{:8.3f}{:8.3f}{:8.3f}{:10.3f}{:8.3f}{:8.3f}{:15.2f}{:15.0f}'.format(\n",
    "    X_test_ready[i, 0], X_test_ready[i, 1], X_test_ready[i, 2], X_test_ready[i, 3], X_test_ready[i, 4], X_test_ready[i, 5], X_test_ready[i, 6],\n",
    "    X_test_ready[i, 7], X_test_ready[i, 8], X_test_ready[i, 9], X_test_ready[i, 10], X_test_ready[i, 11], y_predicha[i], y_umbral[i]\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.7.4 Calculando la precision del entrenamiento:\n",
    "se hace uso del **np.mean**, Calcula la media (promedio) de los valores booleanos. Dado que True se interpreta como 1 y False como 0 en operaciones aritméticas, la media resultante será la proporción de elementos iguales en **y_predicha** e **y_test**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión de entrenamiento: 72.65 %\n"
     ]
    }
   ],
   "source": [
    "print('Precisión de entrenamiento: {:.2f} %'.format(np.mean(y_umbral == y_test) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.7.5 Concluciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede observar que la precision de prediccion es de un 72.65%, lo cual esta por encima del 50% pero casi por muy debajo del 100%, si bien nos predicciones casi acertadas en un 72.65% no es muy confiable para predicciones relacionadas a **enfermedades cardiovasculares**, la precisión del 72.65% podría indicar que el modelo tiene cierto grado de capacidad predictiva, pero puede que no sea suficientemente alto para algunos casos clínicos donde la precisión es crítica."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
